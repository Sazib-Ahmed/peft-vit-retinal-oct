
=== DATASET RUN START: OCT2017 ===

[DATA] Split/Class counts:
class    CNV   DME  DRUSEN  NORMAL  TOTAL
split                                    
test     250   250     250     250   1000
train  28285  9819    7000   45054  90158
val     3142  1091     777    5006  10016
[DATA] Train imbalance: min=7000, max=45054, ratio=6.44
[RAM] Caching split='train' images=90158 as uint8 tensors. Estimated RAM ~ 12.64 GB
[RAM] Cached 90158 images for split='train'
[RAM] Caching split='val' images=10016 as uint8 tensors. Estimated RAM ~ 1.40 GB
[RAM] Cached 10016 images for split='val'
[RAM] Caching split='test' images=1000 as uint8 tensors. Estimated RAM ~ 0.14 GB
[RAM] Cached 1000 images for split='test'
[IMB] Train class counts: [28285, 9819, 7000, 45054]
[IMB] Class-Balanced weights (mean~1): [0.7512, 1.1301, 1.404, 0.7147]
[IMB] Sampler disabled. min=7000 max=45054 ratio=6.44

[DATASET] OCT2017
 - root: D:\AIUB\DSP\Code\Datasets\ZhangLabData\OCT2017_CLEAN_SHAONLY
 - pad_to_square: True
 - cache_in_ram: True
 - classes (4): ['CNV', 'DME', 'DRUSEN', 'NORMAL']
 - split sizes: train=90158 val=10016 test=1000

[MODEL] Creating deit_small_distilled_patch16_224 + VPT-Deep (frozen=True)
[PARAMS] total=21,761,672 trainable=95,240 (0.4377%)
[IMB] Train class counts: [28285, 9819, 7000, 45054]
[IMB] Class-Balanced weights (mean~1): [0.7512, 1.1301, 1.404, 0.7147]
[IMB] Sampler disabled. min=7000 max=45054 ratio=6.44
[OCT2017] Epoch 001/100 | lr=1.00e-04 | train_loss=0.8597 train_acc=80.52% | val_loss=0.5944 val_acc=92.45% val_macroF1=86.64% | ep_time=141.6s peakVRAM=1.73GB
[ES] New best val_loss=0.594410 -> saved runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809\best_model.pth
[OCT2017] Epoch 002/100 | lr=1.50e-04 | train_loss=0.6424 train_acc=90.73% | val_loss=0.5951 val_acc=91.99% val_macroF1=87.03% | ep_time=139.1s peakVRAM=1.73GB
[ES] No improve 1/10
[OCT2017] Epoch 003/100 | lr=2.00e-04 | train_loss=0.6135 train_acc=91.87% | val_loss=0.5567 val_acc=93.80% val_macroF1=89.64% | ep_time=139.0s peakVRAM=1.73GB
[ES] New best val_loss=0.556749 -> saved runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809\best_model.pth
[OCT2017] Epoch 004/100 | lr=2.50e-04 | train_loss=0.6024 train_acc=92.28% | val_loss=0.5333 val_acc=95.06% val_macroF1=91.60% | ep_time=139.2s peakVRAM=1.73GB
[ES] New best val_loss=0.533341 -> saved runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809\best_model.pth
[OCT2017] Epoch 005/100 | lr=3.00e-04 | train_loss=0.5889 train_acc=92.75% | val_loss=0.5275 val_acc=95.63% val_macroF1=92.09% | ep_time=139.4s peakVRAM=1.73GB
[ES] New best val_loss=0.527499 -> saved runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809\best_model.pth
[OCT2017] Epoch 006/100 | lr=3.50e-04 | train_loss=0.5840 train_acc=92.95% | val_loss=0.5297 val_acc=95.40% val_macroF1=92.14% | ep_time=139.3s peakVRAM=1.73GB
[ES] No improve 1/10
[OCT2017] Epoch 007/100 | lr=4.00e-04 | train_loss=0.5754 train_acc=93.31% | val_loss=0.5202 val_acc=95.89% val_macroF1=92.82% | ep_time=138.5s peakVRAM=1.73GB
[ES] New best val_loss=0.520202 -> saved runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809\best_model.pth
[OCT2017] Epoch 008/100 | lr=4.50e-04 | train_loss=0.5742 train_acc=93.49% | val_loss=0.5239 val_acc=95.54% val_macroF1=92.34% | ep_time=138.4s peakVRAM=1.73GB
[ES] No improve 1/10
[OCT2017] Epoch 009/100 | lr=5.00e-04 | train_loss=0.5684 train_acc=93.59% | val_loss=0.5090 val_acc=96.52% val_macroF1=93.78% | ep_time=138.2s peakVRAM=1.73GB
[ES] New best val_loss=0.508981 -> saved runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809\best_model.pth
[OCT2017] Epoch 010/100 | lr=5.00e-04 | train_loss=0.5656 train_acc=93.75% | val_loss=0.5219 val_acc=96.20% val_macroF1=93.24% | ep_time=138.4s peakVRAM=1.73GB
[ES] No improve 1/10
[OCT2017] Epoch 011/100 | lr=5.00e-04 | train_loss=0.5645 train_acc=93.88% | val_loss=0.5120 val_acc=96.59% val_macroF1=93.90% | ep_time=138.2s peakVRAM=1.73GB
[ES] No improve 2/10
[OCT2017] Epoch 012/100 | lr=4.99e-04 | train_loss=0.5556 train_acc=94.18% | val_loss=0.5167 val_acc=96.03% val_macroF1=93.08% | ep_time=138.1s peakVRAM=1.73GB
[ES] No improve 3/10
[OCT2017] Epoch 013/100 | lr=4.99e-04 | train_loss=0.5575 train_acc=94.04% | val_loss=0.5211 val_acc=95.62% val_macroF1=92.50% | ep_time=138.0s peakVRAM=1.73GB
[ES] No improve 4/10
[OCT2017] Epoch 014/100 | lr=4.98e-04 | train_loss=0.5550 train_acc=94.16% | val_loss=0.5080 val_acc=96.30% val_macroF1=93.47% | ep_time=138.0s peakVRAM=1.73GB
[ES] New best val_loss=0.508028 -> saved runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809\best_model.pth
[OCT2017] Epoch 015/100 | lr=4.96e-04 | train_loss=0.5496 train_acc=94.43% | val_loss=0.5046 val_acc=96.78% val_macroF1=93.98% | ep_time=138.4s peakVRAM=1.73GB
[ES] New best val_loss=0.504570 -> saved runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809\best_model.pth
[OCT2017] Epoch 016/100 | lr=4.95e-04 | train_loss=0.5461 train_acc=94.58% | val_loss=0.5083 val_acc=96.72% val_macroF1=94.13% | ep_time=138.1s peakVRAM=1.73GB
[ES] No improve 1/10
[OCT2017] Epoch 017/100 | lr=4.93e-04 | train_loss=0.5460 train_acc=94.63% | val_loss=0.5007 val_acc=96.89% val_macroF1=94.46% | ep_time=138.1s peakVRAM=1.73GB
[ES] New best val_loss=0.500711 -> saved runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809\best_model.pth
[OCT2017] Epoch 018/100 | lr=4.90e-04 | train_loss=0.5482 train_acc=94.50% | val_loss=0.5064 val_acc=96.54% val_macroF1=93.88% | ep_time=138.4s peakVRAM=1.73GB
[ES] No improve 1/10
[OCT2017] Epoch 019/100 | lr=4.88e-04 | train_loss=0.5436 train_acc=94.59% | val_loss=0.5038 val_acc=96.61% val_macroF1=93.96% | ep_time=138.0s peakVRAM=1.73GB
[ES] No improve 2/10
[OCT2017] Epoch 020/100 | lr=4.85e-04 | train_loss=0.5425 train_acc=94.72% | val_loss=0.4991 val_acc=96.81% val_macroF1=94.29% | ep_time=137.4s peakVRAM=1.73GB
[ES] New best val_loss=0.499112 -> saved runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809\best_model.pth
[OCT2017] Epoch 021/100 | lr=4.82e-04 | train_loss=0.5420 train_acc=94.70% | val_loss=0.5025 val_acc=96.79% val_macroF1=94.10% | ep_time=137.6s peakVRAM=1.73GB
[ES] No improve 1/10
[OCT2017] Epoch 022/100 | lr=4.78e-04 | train_loss=0.5404 train_acc=94.74% | val_loss=0.4992 val_acc=96.81% val_macroF1=94.29% | ep_time=137.5s peakVRAM=1.73GB
[ES] No improve 2/10
[OCT2017] Epoch 023/100 | lr=4.75e-04 | train_loss=0.5397 train_acc=94.82% | val_loss=0.4976 val_acc=97.08% val_macroF1=94.76% | ep_time=137.4s peakVRAM=1.73GB
[ES] New best val_loss=0.497608 -> saved runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809\best_model.pth
[OCT2017] Epoch 024/100 | lr=4.71e-04 | train_loss=0.5422 train_acc=94.71% | val_loss=0.4994 val_acc=96.87% val_macroF1=94.33% | ep_time=137.5s peakVRAM=1.73GB
[ES] No improve 1/10
[OCT2017] Epoch 025/100 | lr=4.67e-04 | train_loss=0.5325 train_acc=95.20% | val_loss=0.5042 val_acc=96.35% val_macroF1=93.64% | ep_time=137.4s peakVRAM=1.73GB
[ES] No improve 2/10
[OCT2017] Epoch 026/100 | lr=4.62e-04 | train_loss=0.5357 train_acc=94.94% | val_loss=0.5018 val_acc=96.71% val_macroF1=94.19% | ep_time=137.4s peakVRAM=1.73GB
[ES] No improve 3/10
[OCT2017] Epoch 027/100 | lr=4.57e-04 | train_loss=0.5376 train_acc=94.83% | val_loss=0.4993 val_acc=96.89% val_macroF1=94.55% | ep_time=137.5s peakVRAM=1.73GB
[ES] No improve 4/10
[OCT2017] Epoch 028/100 | lr=4.52e-04 | train_loss=0.5333 train_acc=95.07% | val_loss=0.5020 val_acc=96.78% val_macroF1=94.36% | ep_time=137.5s peakVRAM=1.73GB
[ES] No improve 5/10
[OCT2017] Epoch 029/100 | lr=4.47e-04 | train_loss=0.5340 train_acc=95.09% | val_loss=0.4989 val_acc=97.07% val_macroF1=94.72% | ep_time=137.4s peakVRAM=1.73GB
[ES] No improve 6/10
[OCT2017] Epoch 030/100 | lr=4.42e-04 | train_loss=0.5339 train_acc=95.05% | val_loss=0.4956 val_acc=97.09% val_macroF1=94.77% | ep_time=137.5s peakVRAM=1.73GB
[ES] New best val_loss=0.495639 -> saved runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809\best_model.pth
[OCT2017] Epoch 031/100 | lr=4.36e-04 | train_loss=0.5302 train_acc=95.23% | val_loss=0.4971 val_acc=96.92% val_macroF1=94.57% | ep_time=137.6s peakVRAM=1.73GB
[ES] No improve 1/10
[OCT2017] Epoch 032/100 | lr=4.30e-04 | train_loss=0.5323 train_acc=95.10% | val_loss=0.4977 val_acc=96.95% val_macroF1=94.56% | ep_time=137.4s peakVRAM=1.73GB
[ES] No improve 2/10
[OCT2017] Epoch 033/100 | lr=4.24e-04 | train_loss=0.5323 train_acc=95.16% | val_loss=0.4970 val_acc=97.07% val_macroF1=94.64% | ep_time=137.4s peakVRAM=1.73GB
[ES] No improve 3/10
[OCT2017] Epoch 034/100 | lr=4.17e-04 | train_loss=0.5280 train_acc=95.29% | val_loss=0.4988 val_acc=96.93% val_macroF1=94.56% | ep_time=137.6s peakVRAM=1.73GB
[ES] No improve 4/10
[OCT2017] Epoch 035/100 | lr=4.11e-04 | train_loss=0.5332 train_acc=95.04% | val_loss=0.5022 val_acc=96.56% val_macroF1=93.93% | ep_time=137.5s peakVRAM=1.73GB
[ES] No improve 5/10
[OCT2017] Epoch 036/100 | lr=4.04e-04 | train_loss=0.5293 train_acc=95.24% | val_loss=0.5024 val_acc=96.69% val_macroF1=94.17% | ep_time=137.5s peakVRAM=1.73GB
[ES] No improve 6/10
[OCT2017] Epoch 037/100 | lr=3.97e-04 | train_loss=0.5325 train_acc=95.05% | val_loss=0.5033 val_acc=96.66% val_macroF1=94.16% | ep_time=137.5s peakVRAM=1.73GB
[ES] No improve 7/10
[OCT2017] Epoch 038/100 | lr=3.90e-04 | train_loss=0.5268 train_acc=95.35% | val_loss=0.4957 val_acc=97.09% val_macroF1=94.93% | ep_time=137.5s peakVRAM=1.73GB
[ES] No improve 8/10
[OCT2017] Epoch 039/100 | lr=3.82e-04 | train_loss=0.5273 train_acc=95.34% | val_loss=0.4986 val_acc=96.91% val_macroF1=94.63% | ep_time=137.5s peakVRAM=1.73GB
[ES] No improve 9/10
[OCT2017] Epoch 040/100 | lr=3.75e-04 | train_loss=0.5268 train_acc=95.30% | val_loss=0.5058 val_acc=96.28% val_macroF1=93.63% | ep_time=137.5s peakVRAM=1.73GB
[ES] No improve 10/10
[OCT2017] Early stopping triggered.
[CAL] Fitting temperature scaling on VAL set...
[CAL] Learned temperature T = 0.5476

------------------------------------------------------------------------------------------
[OCT2017] TEST classification report (uncalibrated)
------------------------------------------------------------------------------------------
              precision    recall  f1-score   support

         CNV     0.7267    1.0000    0.8418       250
         DME     1.0000    0.9040    0.9496       250
      DRUSEN     0.9886    0.6920    0.8141       250
      NORMAL     0.9686    0.9880    0.9782       250

    accuracy                         0.8960      1000
   macro avg     0.9210    0.8960    0.8959      1000
weighted avg     0.9210    0.8960    0.8959      1000


==========================================================================================
[OCT2017] TEST summary (uncalibrated): Acc=89.60% MacroF1=89.59% ECE=0.0850 NLL=0.3109 Brier=0.1542
[OCT2017] Macro-AUC=0.9957
[OCT2017] TEMP-SCALED (T=0.548): ECE=0.0610 NLL=0.2972 Brier=0.1649
[OCT2017] Params trainable: 95,240 (0.4377%)
[OCT2017] Adapter-only size: 0.37 MB
[OCT2017] Inference latency (B=1): 13.410 ms/img (74.6 imgs/s), peakVRAM=0.10GB
[OCT2017] Inference throughput (B=64): 2128.0 imgs/s, peakVRAM=0.32GB
[OCT2017] Outputs saved in: runs\OCT2017\deit_small_vptdeep_frozen_4c\20251225-190809
==========================================================================================

