{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a538312a-67ac-440d-819d-f3633fa4e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DeiT (ViT) + LoRA Pipeline for Retinal OCT Classification\n",
    "========================================================\n",
    "Supports TWO modes (set CONFIG[\"freeze_backbone\"]):\n",
    "1) Frozen backbone:   LoRA + head(s) train, backbone frozen\n",
    "2) Unfrozen backbone: LoRA + FULL fine-tuning (backbone + LoRA + head(s))\n",
    "\n",
    "Backbone: deit_small_distilled_patch16_224 (timm)\n",
    "Adaptation: LoRA injected into attention qkv\n",
    "\n",
    "Paper-grade evaluation:\n",
    "  * Accuracy, Macro-F1\n",
    "  * ROC curves + per-class AUC + Macro-AUC\n",
    "  * Confusion matrix (normalized)\n",
    "  * Classification report heatmap\n",
    "  * Sensitivity & Specificity per class\n",
    "  * Calibration: ECE, NLL, Brier + Reliability diagram\n",
    "  * Optional Temperature scaling (val-set) for publication-grade calibration\n",
    "  * t-SNE of DeiT features (CLS token)\n",
    "  * Efficiency: trainable params, % trainable, adapter-only checkpoint size,\n",
    "               inference latency/throughput, peak VRAM\n",
    "\n",
    "Requirements:\n",
    "  pip install timm peft scikit-learn pandas matplotlib seaborn opencv-python\n",
    "\"\"\"\n",
    "\n",
    "# ==========================================\n",
    "# 0. IMPORTS\n",
    "# ==========================================\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "import gc\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import timm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 1. USER SETTINGS (EDIT THESE)\n",
    "# ==========================================\n",
    "DATASET_CONFIGS: Dict[str, Dict] = {\n",
    "    \"C8\": {\n",
    "        \"root\": r\"D:\\AIUB\\DSP\\Code\\Datasets\\C8\\RetinalOCT_Dataset\",\n",
    "        \"pad_to_square\": True,\n",
    "        \"cache_in_ram\": True,   # OK for smaller datasets\n",
    "    },\n",
    "    \"OCT2017\": {\n",
    "        \"root\": r\"D:\\AIUB\\DSP\\Code\\Datasets\\OCT2017\\OCT2017\",\n",
    "        \"pad_to_square\": True,\n",
    "        \"cache_in_ram\": False,  # RECOMMENDED: OCT2017 can be huge; True may crash RAM\n",
    "    },\n",
    "}\n",
    "\n",
    "RUN_DATASETS = [\"C8\", \"OCT2017\"]\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. GLOBAL CONFIG\n",
    "# ==========================================\n",
    "CONFIG = {\n",
    "    # --- Repro / device ---\n",
    "    \"seed\": 42,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"amp_enabled\": True,\n",
    "    \"num_workers\": 0,  # Windows-safe default; you can try 2-4 if stable.\n",
    "\n",
    "    # --- Model ---\n",
    "    \"model_name\": \"deit_small_distilled_patch16_224\",\n",
    "    \"img_size\": 224,\n",
    "\n",
    "    # --- Training ---\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 2,\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \"warmup_epochs\": 1,\n",
    "    \"patience\": 10,\n",
    "    \"label_smoothing\": 0.1,\n",
    "\n",
    "    # --- Mode ---\n",
    "    # True  = Frozen backbone (LoRA + heads train)\n",
    "    # False = Unfrozen backbone (LoRA + FULL fine-tuning)\n",
    "    \"freeze_backbone\": False,\n",
    "\n",
    "    # --- LoRA ---\n",
    "    \"lora_r\": 8,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.1,\n",
    "\n",
    "    # --- Calibration ---\n",
    "    \"use_temperature_scaling\": True,\n",
    "\n",
    "    # --- Inference benchmark ---\n",
    "    \"bench_merge_lora\": True,\n",
    "    \"bench_warmup_iters\": 50,\n",
    "    \"bench_timed_iters\": 300,\n",
    "    \"bench_latency_batch\": 1,\n",
    "    \"bench_throughput_batch\": 64,\n",
    "}\n",
    "\n",
    "\n",
    "def get_mode_strings() -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      mode_tag: used in folder names\n",
    "      mode_title: used in prints/plots\n",
    "    \"\"\"\n",
    "    if CONFIG[\"freeze_backbone\"]:\n",
    "        return \"lora_frozen\", \"LoRA (Frozen backbone)\"\n",
    "    return \"lora_fullft\", \"LoRA + Full Fine-Tuning (Unfrozen backbone)\"\n",
    "\n",
    "\n",
    "# Seeds\n",
    "torch.manual_seed(CONFIG[\"seed\"])\n",
    "np.random.seed(CONFIG[\"seed\"])\n",
    "random.seed(CONFIG[\"seed\"])\n",
    "if CONFIG[\"device\"].type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(CONFIG[\"seed\"])\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. UTILS: PAD-TO-SQUARE + DATASET\n",
    "# ==========================================\n",
    "def pad_to_square_np(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Pads an HxWxC image to square with black borders.\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    if h == w:\n",
    "        return image\n",
    "    diff = abs(h - w)\n",
    "    pad_1 = diff // 2\n",
    "    pad_2 = diff - pad_1\n",
    "    if h > w:\n",
    "        padding = ((0, 0), (pad_1, pad_2), (0, 0))\n",
    "    else:\n",
    "        padding = ((pad_1, pad_2), (0, 0), (0, 0))\n",
    "    return np.pad(image, padding, mode=\"constant\", constant_values=0)\n",
    "\n",
    "\n",
    "def list_images_by_class(split_dir: str) -> Tuple[List[str], List[int], List[str]]:\n",
    "    \"\"\"Returns (paths, labels, class_names) where label indices follow sorted class_names.\"\"\"\n",
    "    class_names = sorted([d for d in os.listdir(split_dir) if os.path.isdir(os.path.join(split_dir, d))])\n",
    "    class_to_idx = {c: i for i, c in enumerate(class_names)}\n",
    "\n",
    "    paths, labels = [], []\n",
    "    for c in class_names:\n",
    "        cdir = os.path.join(split_dir, c)\n",
    "        for fn in os.listdir(cdir):\n",
    "            p = os.path.join(cdir, fn)\n",
    "            if os.path.isfile(p):\n",
    "                paths.append(p)\n",
    "                labels.append(class_to_idx[c])\n",
    "    return paths, labels, class_names\n",
    "\n",
    "\n",
    "class OCTFolderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Folder-based dataset with optional RAM caching.\n",
    "    Expected structure:\n",
    "      root/train/<class>/*.png|jpg\n",
    "      root/val/<class>/*.png|jpg\n",
    "      root/test/<class>/*.png|jpg\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: str,\n",
    "        split: str,\n",
    "        img_size: int,\n",
    "        transform=None,\n",
    "        pad_to_square: bool = False,\n",
    "        cache_in_ram: bool = False,\n",
    "        class_names: Optional[List[str]] = None\n",
    "    ):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.pad_to_square = pad_to_square\n",
    "        self.cache_in_ram = cache_in_ram\n",
    "\n",
    "        split_dir = os.path.join(root_dir, split)\n",
    "\n",
    "        # Ensure consistent class order across splits (use train split as source of truth)\n",
    "        if class_names is None:\n",
    "            _, _, class_names = list_images_by_class(split_dir)\n",
    "        self.class_names = class_names\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.class_names)}\n",
    "\n",
    "        # Build path list\n",
    "        self.paths = []\n",
    "        self.labels = []\n",
    "        for c in self.class_names:\n",
    "            cdir = os.path.join(split_dir, c)\n",
    "            if not os.path.isdir(cdir):\n",
    "                continue\n",
    "            for fn in os.listdir(cdir):\n",
    "                p = os.path.join(cdir, fn)\n",
    "                if os.path.isfile(p):\n",
    "                    self.paths.append(p)\n",
    "                    self.labels.append(self.class_to_idx[c])\n",
    "\n",
    "        self.cached_images = None\n",
    "        if self.cache_in_ram:\n",
    "            self.cached_images = []\n",
    "            print(f\"[INFO] RAM-caching: loading {len(self.paths)} images for split='{split}' ...\")\n",
    "            for p in tqdm(self.paths, desc=f\"--> Caching {split}\", leave=False):\n",
    "                img = cv2.imread(p)\n",
    "                if img is None:\n",
    "                    self.cached_images.append(np.zeros((img_size, img_size, 3), dtype=np.uint8))\n",
    "                    continue\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                if self.pad_to_square:\n",
    "                    img = pad_to_square_np(img)\n",
    "                img = cv2.resize(img, (img_size, img_size), interpolation=cv2.INTER_AREA)\n",
    "                self.cached_images.append(img)\n",
    "            print(f\"[SUCCESS] RAM-cached {len(self.cached_images)} images for '{split}'.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def _load_image(self, idx: int) -> np.ndarray:\n",
    "        if self.cache_in_ram and self.cached_images is not None:\n",
    "            return self.cached_images[idx]\n",
    "\n",
    "        p = self.paths[idx]\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            return np.zeros((self.img_size, self.img_size, 3), dtype=np.uint8)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.pad_to_square:\n",
    "            img = pad_to_square_np(img)\n",
    "        img = cv2.resize(img, (self.img_size, self.img_size), interpolation=cv2.INTER_AREA)\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img = self._load_image(idx)\n",
    "        label = self.labels[idx]\n",
    "        img_pil = Image.fromarray(img)\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(img_pil)\n",
    "        else:\n",
    "            x = transforms.ToTensor()(img_pil)\n",
    "        return x, label\n",
    "\n",
    "\n",
    "def build_transforms():\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    eval_tf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return train_tf, eval_tf\n",
    "\n",
    "\n",
    "def build_dataloaders(dataset_name: str, ds_cfg: Dict) -> Tuple[DataLoader, DataLoader, DataLoader, List[str]]:\n",
    "    root = ds_cfg[\"root\"]\n",
    "    pad_sq = ds_cfg.get(\"pad_to_square\", False)\n",
    "    cache = ds_cfg.get(\"cache_in_ram\", False)\n",
    "\n",
    "    train_tf, eval_tf = build_transforms()\n",
    "\n",
    "    train_split_dir = os.path.join(root, \"train\")\n",
    "    _, _, class_names = list_images_by_class(train_split_dir)\n",
    "\n",
    "    train_ds = OCTFolderDataset(root, \"train\", CONFIG[\"img_size\"], train_tf, pad_sq, cache, class_names)\n",
    "    val_ds   = OCTFolderDataset(root, \"val\",   CONFIG[\"img_size\"], eval_tf, pad_sq, cache, class_names)\n",
    "    test_ds  = OCTFolderDataset(root, \"test\",  CONFIG[\"img_size\"], eval_tf, pad_sq, cache, class_names)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=CONFIG[\"batch_size\"], shuffle=True,\n",
    "        num_workers=CONFIG[\"num_workers\"], pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=CONFIG[\"batch_size\"], shuffle=False,\n",
    "        num_workers=CONFIG[\"num_workers\"], pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=CONFIG[\"batch_size\"], shuffle=False,\n",
    "        num_workers=CONFIG[\"num_workers\"], pin_memory=True\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[DATASET] {dataset_name}\")\n",
    "    print(f\" - root: {root}\")\n",
    "    print(f\" - pad_to_square: {pad_sq}\")\n",
    "    print(f\" - cache_in_ram: {cache}\")\n",
    "    print(f\" - classes ({len(class_names)}): {class_names}\")\n",
    "    print(f\" - split sizes: train={len(train_ds)} val={len(val_ds)} test={len(test_ds)}\")\n",
    "    return train_loader, val_loader, test_loader, class_names\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. MODEL: TIMM + PEFT LoRA\n",
    "# ==========================================\n",
    "class TimmVisionWrapper(nn.Module):\n",
    "    \"\"\"Bridge wrapper for PEFT -> timm vision model.\"\"\"\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input_ids=None, pixel_values=None, **kwargs):\n",
    "        # PEFT will pass the first positional tensor into input_ids\n",
    "        if input_ids is not None:\n",
    "            x = input_ids\n",
    "        elif pixel_values is not None:\n",
    "            x = pixel_values\n",
    "        else:\n",
    "            x = kwargs.get(\"x\", None)\n",
    "            if x is None:\n",
    "                raise ValueError(\"No input tensor provided.\")\n",
    "        return self.model(x)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        if hasattr(self.model, \"forward_features\"):\n",
    "            return self.model.forward_features(x)\n",
    "        raise AttributeError(\"Underlying timm model has no forward_features()\")\n",
    "\n",
    "\n",
    "def unfreeze_all_params(model: nn.Module):\n",
    "    \"\"\"LoRA + full fine-tuning: train EVERYTHING (backbone + LoRA + heads).\"\"\"\n",
    "    for _, p in model.named_parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "\n",
    "def freeze_backbone_keep_lora_and_heads(model: nn.Module):\n",
    "    \"\"\"\n",
    "    Frozen-backbone PEFT:\n",
    "      - freeze everything\n",
    "      - unfreeze LoRA params + classification head(s)\n",
    "    \"\"\"\n",
    "    for _, p in model.named_parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    for n, p in model.named_parameters():\n",
    "        if \"lora_\" in n:\n",
    "            p.requires_grad = True\n",
    "\n",
    "    head_keywords = [\".head.\", \".head_dist.\", \"head.\", \"head_dist.\", \"modules_to_save\"]\n",
    "    for n, p in model.named_parameters():\n",
    "        if any(k in n for k in head_keywords):\n",
    "            p.requires_grad = True\n",
    "\n",
    "\n",
    "def count_params(model: nn.Module) -> Tuple[int, int, float]:\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    pct = 100.0 * trainable / max(total, 1)\n",
    "    return total, trainable, pct\n",
    "\n",
    "\n",
    "def create_deit_lora_model(num_classes: int) -> nn.Module:\n",
    "    mode_tag, mode_title = get_mode_strings()\n",
    "    print(f\"\\n[MODEL] Creating {CONFIG['model_name']} + LoRA | mode={mode_title}\")\n",
    "\n",
    "    base_model = timm.create_model(\n",
    "        CONFIG[\"model_name\"],\n",
    "        pretrained=True,\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "    wrapped = TimmVisionWrapper(base_model)\n",
    "\n",
    "    modules_to_save = [\"head\"]\n",
    "    if hasattr(base_model, \"head_dist\"):\n",
    "        modules_to_save.append(\"head_dist\")\n",
    "\n",
    "    lora_cfg = LoraConfig(\n",
    "        r=CONFIG[\"lora_r\"],\n",
    "        lora_alpha=CONFIG[\"lora_alpha\"],\n",
    "        target_modules=[\"qkv\"],\n",
    "        lora_dropout=CONFIG[\"lora_dropout\"],\n",
    "        bias=\"none\",\n",
    "        modules_to_save=modules_to_save,\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(wrapped, lora_cfg).to(CONFIG[\"device\"])\n",
    "\n",
    "    if CONFIG[\"freeze_backbone\"]:\n",
    "        freeze_backbone_keep_lora_and_heads(model)\n",
    "    else:\n",
    "        # PEFT often freezes base weights by default; this makes it TRUE full fine-tuning.\n",
    "        unfreeze_all_params(model)\n",
    "\n",
    "    total, trainable, pct = count_params(model)\n",
    "    print(f\"[PARAMS] total={total:,} trainable={trainable:,} ({pct:.3f}%)\")\n",
    "\n",
    "    if (not CONFIG[\"freeze_backbone\"]) and pct < 90.0:\n",
    "        print(\"[WARN] Unfrozen mode selected but trainable% is unexpectedly low. \"\n",
    "              \"Double-check requires_grad flags.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def forward_logits(model: nn.Module, x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Handle distilled DeiT outputs safely.\"\"\"\n",
    "    out = model(x)\n",
    "    if isinstance(out, (tuple, list)):\n",
    "        return (out[0] + out[1]) / 2.0\n",
    "    return out\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 5. METRICS: CALIBRATION + MEDICAL\n",
    "# ==========================================\n",
    "def compute_ece(probs: np.ndarray, labels: np.ndarray, n_bins: int = 15) -> float:\n",
    "    conf = probs.max(axis=1)\n",
    "    pred = probs.argmax(axis=1)\n",
    "    acc = (pred == labels).astype(float)\n",
    "\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    n = len(labels)\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i + 1]\n",
    "        m = (conf > lo) & (conf <= hi)\n",
    "        if not np.any(m):\n",
    "            continue\n",
    "        ece += (m.sum() / n) * abs(acc[m].mean() - conf[m].mean())\n",
    "    return float(ece)\n",
    "\n",
    "\n",
    "def compute_brier(probs: np.ndarray, labels: np.ndarray, num_classes: int) -> float:\n",
    "    one_hot = np.eye(num_classes)[labels]\n",
    "    return float(np.mean(np.sum((probs - one_hot) ** 2, axis=1)))\n",
    "\n",
    "\n",
    "def compute_nll(probs: np.ndarray, labels: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    p = np.clip(probs, eps, 1.0)\n",
    "    return float((-np.log(p[np.arange(len(labels)), labels])).mean())\n",
    "\n",
    "\n",
    "def plot_reliability_diagram(probs: np.ndarray, labels: np.ndarray, n_bins: int, title: str, save_path: str):\n",
    "    conf = probs.max(axis=1)\n",
    "    pred = probs.argmax(axis=1)\n",
    "    correct = (pred == labels).astype(float)\n",
    "\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    centers = (bins[:-1] + bins[1:]) / 2.0\n",
    "\n",
    "    accs, confs = [], []\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i + 1]\n",
    "        m = (conf > lo) & (conf <= hi)\n",
    "        if np.any(m):\n",
    "            accs.append(correct[m].mean())\n",
    "            confs.append(conf[m].mean())\n",
    "        else:\n",
    "            accs.append(0.0)\n",
    "            confs.append((lo + hi) / 2.0)\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot([0, 1], [0, 1], \"--\", color=\"gray\", label=\"Perfect\")\n",
    "    plt.bar(centers, accs, width=1.0 / n_bins, alpha=0.7, edgecolor=\"black\", label=\"Empirical\")\n",
    "    plt.xlabel(\"Confidence\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def sensitivity_specificity_from_cm(cm: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    k = cm.shape[0]\n",
    "    sens, spec = [], []\n",
    "    for i in range(k):\n",
    "        tp = cm[i, i]\n",
    "        fn = cm[i, :].sum() - tp\n",
    "        fp = cm[:, i].sum() - tp\n",
    "        tn = cm.sum() - (tp + fn + fp)\n",
    "        sens.append(tp / (tp + fn + 1e-12))\n",
    "        spec.append(tn / (tn + fp + 1e-12))\n",
    "    return np.array(sens), np.array(spec)\n",
    "\n",
    "\n",
    "def plot_sens_spec(cm: np.ndarray, class_names: List[str], title: str, save_path: str):\n",
    "    sens, spec = sensitivity_specificity_from_cm(cm)\n",
    "    x = np.arange(len(class_names))\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - 0.2, sens, width=0.4, label=\"Sensitivity (Recall)\")\n",
    "    plt.bar(x + 0.2, spec, width=0.4, label=\"Specificity\")\n",
    "    plt.xticks(x, class_names, rotation=45, ha=\"right\")\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion(cm: np.ndarray, class_names: List[str], title: str, save_path: str):\n",
    "    cm_sum = cm.sum(axis=1)[:, np.newaxis]\n",
    "    cm_norm = np.divide(cm.astype(float), cm_sum, out=np.zeros_like(cm, dtype=float), where=cm_sum != 0)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_norm, annot=True, fmt=\".2%\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={\"label\": \"Normalized Frequency\"})\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_classification_report_heatmap(report_str: str, title: str, save_path: str):\n",
    "    lines = report_str.split(\"\\n\")\n",
    "    rows = []\n",
    "    for line in lines[2:-5]:\n",
    "        parts = [p for p in line.split(\" \") if p]\n",
    "        if len(parts) >= 4:\n",
    "            rows.append([parts[0], float(parts[1]), float(parts[2]), float(parts[3])])\n",
    "    if not rows:\n",
    "        print(\"[WARN] Could not parse classification report for heatmap.\")\n",
    "        return\n",
    "    df = pd.DataFrame(rows, columns=[\"class\", \"precision\", \"recall\", \"f1\"]).set_index(\"class\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(df, annot=True, cmap=\"Blues\", fmt=\".3f\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curves(labels: np.ndarray, probs: np.ndarray, class_names: List[str], title: str, save_path: str):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    k = len(class_names)\n",
    "    colors = plt.colormaps.get_cmap(\"viridis\")(np.linspace(0, 1, k))\n",
    "    for i, cname in enumerate(class_names):\n",
    "        if i in np.unique(labels):\n",
    "            fpr, tpr, _ = roc_curve((labels == i).astype(int), probs[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, color=colors[i], lw=2, label=f\"{cname} (AUC={roc_auc:.3f})\")\n",
    "        else:\n",
    "            plt.plot([], [], color=colors[i], lw=2, label=f\"{cname} (no samples)\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", lw=1.5, label=\"Chance\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR\")\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 6. TEMPERATURE SCALING (VAL -> TEST)\n",
    "# ==========================================\n",
    "class TemperatureScaler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.0)\n",
    "\n",
    "    def forward(self, logits: torch.Tensor) -> torch.Tensor:\n",
    "        return logits / self.temperature.clamp(min=1e-6)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_T(self) -> float:\n",
    "        return float(self.temperature.detach().cpu().item())\n",
    "\n",
    "\n",
    "def collect_logits_labels(model: nn.Module, loader: DataLoader) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.eval()\n",
    "    all_logits, all_labels = [], []\n",
    "    with torch.inference_mode():\n",
    "        for x, y in tqdm(loader, desc=\"--> Collect logits\", leave=False):\n",
    "            x = x.to(CONFIG[\"device\"], non_blocking=True)\n",
    "            y = y.to(CONFIG[\"device\"], non_blocking=True)\n",
    "            with torch.autocast(device_type=CONFIG[\"device\"].type, enabled=CONFIG[\"amp_enabled\"]):\n",
    "                logits = forward_logits(model, x)\n",
    "            all_logits.append(logits.detach())\n",
    "            all_labels.append(y.detach())\n",
    "    return torch.cat(all_logits, dim=0), torch.cat(all_labels, dim=0)\n",
    "\n",
    "\n",
    "def fit_temperature_on_val(model: nn.Module, val_loader: DataLoader) -> TemperatureScaler:\n",
    "    print(\"[CAL] Fitting temperature scaling on VAL set...\")\n",
    "    logits, labels = collect_logits_labels(model, val_loader)\n",
    "    scaler = TemperatureScaler().to(CONFIG[\"device\"])\n",
    "    nll_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.LBFGS([scaler.temperature], lr=0.1, max_iter=50)\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss = nll_criterion(scaler(logits), labels)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    print(f\"[CAL] Learned temperature T = {scaler.get_T():.4f}\")\n",
    "    return scaler\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 7. TRAINING ENGINE\n",
    "# ==========================================\n",
    "@dataclass\n",
    "class RunPaths:\n",
    "    out_dir: str\n",
    "    best_model_path: str\n",
    "    last_model_path: str\n",
    "    history_csv: str\n",
    "    summary_json: str\n",
    "    adapter_dir: str\n",
    "\n",
    "\n",
    "def make_run_paths(dataset_name: str, num_classes: int) -> RunPaths:\n",
    "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    mode_tag, _ = get_mode_strings()\n",
    "    out_dir = os.path.join(\"runs\", f\"{dataset_name}\", f\"deit_small_{mode_tag}_{num_classes}c\", ts)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    return RunPaths(\n",
    "        out_dir=out_dir,\n",
    "        best_model_path=os.path.join(out_dir, \"best_val_loss.pth\"),\n",
    "        last_model_path=os.path.join(out_dir, \"last_epoch.pth\"),\n",
    "        history_csv=os.path.join(out_dir, \"history.csv\"),\n",
    "        summary_json=os.path.join(out_dir, \"summary.json\"),\n",
    "        adapter_dir=os.path.join(out_dir, \"adapter_only\"),\n",
    "    )\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience: int, path: str):\n",
    "        self.patience = patience\n",
    "        self.path = path\n",
    "        self.best = None\n",
    "        self.counter = 0\n",
    "        self.stop = False\n",
    "\n",
    "    def __call__(self, val_loss: float, model: nn.Module):\n",
    "        score = -val_loss\n",
    "        if self.best is None or score > self.best:\n",
    "            self.best = score\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "            print(f\"[ES] Saved best checkpoint -> {self.path}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"[ES] no improve: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop = True\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    if CONFIG[\"device\"].type == \"cuda\":\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    scaler = torch.amp.GradScaler(enabled=CONFIG[\"amp_enabled\"])\n",
    "    t0 = time.time()\n",
    "\n",
    "    for x, y in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        x = x.to(CONFIG[\"device\"], non_blocking=True)\n",
    "        y = y.to(CONFIG[\"device\"], non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.autocast(device_type=CONFIG[\"device\"].type, enabled=CONFIG[\"amp_enabled\"]):\n",
    "            out = model(x)\n",
    "            if isinstance(out, (tuple, list)):\n",
    "                loss = 0.5 * (criterion(out[0], y) + criterion(out[1], y))\n",
    "                logits = (out[0] + out[1]) / 2.0\n",
    "            else:\n",
    "                loss = criterion(out, y)\n",
    "                logits = out\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += float(loss.item()) * y.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += int((pred == y).sum().item())\n",
    "        total += y.size(0)\n",
    "\n",
    "    epoch_time = time.time() - t0\n",
    "    peak_mem_gb = 0.0\n",
    "    if CONFIG[\"device\"].type == \"cuda\":\n",
    "        peak_mem_gb = torch.cuda.max_memory_allocated() / (1024**3)\n",
    "\n",
    "    return total_loss / max(total, 1), correct / max(total, 1), epoch_time, peak_mem_gb\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_y, all_p = [], []\n",
    "\n",
    "    for x, y in tqdm(loader, desc=\"Val\", leave=False):\n",
    "        x = x.to(CONFIG[\"device\"], non_blocking=True)\n",
    "        y = y.to(CONFIG[\"device\"], non_blocking=True)\n",
    "\n",
    "        with torch.autocast(device_type=CONFIG[\"device\"].type, enabled=CONFIG[\"amp_enabled\"]):\n",
    "            out = model(x)\n",
    "            if isinstance(out, (tuple, list)):\n",
    "                loss = 0.5 * (criterion(out[0], y) + criterion(out[1], y))\n",
    "                logits = (out[0] + out[1]) / 2.0\n",
    "            else:\n",
    "                loss = criterion(out, y)\n",
    "                logits = out\n",
    "\n",
    "        total_loss += float(loss.item()) * y.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += int((pred == y).sum().item())\n",
    "        total += y.size(0)\n",
    "\n",
    "        all_y.append(y.detach().cpu().numpy())\n",
    "        all_p.append(pred.detach().cpu().numpy())\n",
    "\n",
    "    y_np = np.concatenate(all_y)\n",
    "    p_np = np.concatenate(all_p)\n",
    "    macro_f1 = float(f1_score(y_np, p_np, average=\"macro\"))\n",
    "    return total_loss / max(total, 1), correct / max(total, 1), macro_f1\n",
    "\n",
    "\n",
    "def save_adapter_only(model: nn.Module, out_dir: str) -> int:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    try:\n",
    "        model.save_pretrained(out_dir)\n",
    "        size = 0\n",
    "        for root, _, files in os.walk(out_dir):\n",
    "            for f in files:\n",
    "                size += os.path.getsize(os.path.join(root, f))\n",
    "        return size\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not save adapter-only checkpoint: {e}\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def train_engine(dataset_name: str, train_loader, val_loader, class_names: List[str], run_paths: RunPaths):\n",
    "    num_classes = len(class_names)\n",
    "    model = create_deit_lora_model(num_classes)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=CONFIG[\"label_smoothing\"])\n",
    "\n",
    "    # Optimizer: single-group for frozen, two-group for unfrozen (lower LR backbone)\n",
    "    if CONFIG[\"freeze_backbone\"]:\n",
    "        trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "        optimizer = optim.AdamW(trainable_params, lr=CONFIG[\"lr\"], weight_decay=CONFIG[\"weight_decay\"])\n",
    "    else:\n",
    "        backbone_params = []\n",
    "        lora_head_params = []\n",
    "        for n, p in model.named_parameters():\n",
    "            if not p.requires_grad:\n",
    "                continue\n",
    "            if (\"lora_\" in n) or (\"head\" in n) or (\"head_dist\" in n) or (\"modules_to_save\" in n):\n",
    "                lora_head_params.append(p)\n",
    "            else:\n",
    "                backbone_params.append(p)\n",
    "\n",
    "        if len(backbone_params) == 0 or len(lora_head_params) == 0:\n",
    "            print(\"[WARN] One optimizer group is empty. Falling back to single group optimizer.\")\n",
    "            trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "            optimizer = optim.AdamW(trainable_params, lr=CONFIG[\"lr\"], weight_decay=CONFIG[\"weight_decay\"])\n",
    "        else:\n",
    "            optimizer = optim.AdamW(\n",
    "                [\n",
    "                    {\"params\": backbone_params, \"lr\": CONFIG[\"lr\"] * 0.1},\n",
    "                    {\"params\": lora_head_params, \"lr\": CONFIG[\"lr\"]},\n",
    "                ],\n",
    "                weight_decay=CONFIG[\"weight_decay\"]\n",
    "            )\n",
    "\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < CONFIG[\"warmup_epochs\"]:\n",
    "            return float(epoch + 1) / float(CONFIG[\"warmup_epochs\"])\n",
    "        return 0.5 * (1 + math.cos(math.pi *\n",
    "                                   (epoch - CONFIG[\"warmup_epochs\"]) /\n",
    "                                   max(1, (CONFIG[\"epochs\"] - CONFIG[\"warmup_epochs\"]))))\n",
    "\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "    early_stop = EarlyStopping(CONFIG[\"patience\"], run_paths.best_model_path)\n",
    "\n",
    "    history = {\n",
    "        \"epoch\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_macro_f1\": [],\n",
    "        \"lr_backbone\": [],\n",
    "        \"lr_lora_head\": [],\n",
    "        \"epoch_time_sec\": [],\n",
    "        \"train_peak_vram_gb\": [],\n",
    "    }\n",
    "\n",
    "    total_train_t0 = time.time()\n",
    "\n",
    "    for ep in range(1, CONFIG[\"epochs\"] + 1):\n",
    "        train_loss, train_acc, ep_time, peak_vram = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "        val_loss, val_acc, val_macro_f1 = validate_one_epoch(model, val_loader, criterion)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Log both LR groups (if single group, both = same)\n",
    "        lr_backbone = float(optimizer.param_groups[0][\"lr\"])\n",
    "        lr_lorahead = float(optimizer.param_groups[-1][\"lr\"])\n",
    "\n",
    "        history[\"epoch\"].append(ep)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"val_macro_f1\"].append(val_macro_f1)\n",
    "        history[\"lr_backbone\"].append(lr_backbone)\n",
    "        history[\"lr_lora_head\"].append(lr_lorahead)\n",
    "        history[\"epoch_time_sec\"].append(ep_time)\n",
    "        history[\"train_peak_vram_gb\"].append(peak_vram)\n",
    "\n",
    "        if CONFIG[\"freeze_backbone\"]:\n",
    "            lr_str = f\"lr={lr_backbone:.2e}\"\n",
    "        else:\n",
    "            lr_str = f\"lr_backbone={lr_backbone:.2e} lr_lora/head={lr_lorahead:.2e}\"\n",
    "\n",
    "        print(\n",
    "            f\"[{dataset_name}] Epoch {ep:03d}/{CONFIG['epochs']:03d} | \"\n",
    "            f\"{lr_str} | \"\n",
    "            f\"train_loss={train_loss:.4f} train_acc={train_acc*100:.2f}% | \"\n",
    "            f\"val_loss={val_loss:.4f} val_acc={val_acc*100:.2f}% val_macroF1={val_macro_f1*100:.2f}% | \"\n",
    "            f\"ep_time={ep_time:.1f}s peakVRAM={peak_vram:.2f}GB\"\n",
    "        )\n",
    "\n",
    "        early_stop(val_loss, model)\n",
    "        if early_stop.stop:\n",
    "            print(f\"[{dataset_name}] Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    total_train_time = time.time() - total_train_t0\n",
    "\n",
    "    torch.save(model.state_dict(), run_paths.last_model_path)\n",
    "    pd.DataFrame(history).to_csv(run_paths.history_csv, index=False)\n",
    "\n",
    "    if os.path.exists(run_paths.best_model_path):\n",
    "        model.load_state_dict(torch.load(run_paths.best_model_path, map_location=CONFIG[\"device\"]))\n",
    "\n",
    "    adapter_bytes = save_adapter_only(model, run_paths.adapter_dir)\n",
    "    total_p, trainable_p, trainable_pct = count_params(model)\n",
    "\n",
    "    return model, history, total_train_time, (total_p, trainable_p, trainable_pct), adapter_bytes\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 8. PLOTS: TRAIN CURVES + LR\n",
    "# ==========================================\n",
    "def plot_training_curves(history: Dict, title: str, out_dir: str):\n",
    "    epochs = history[\"epoch\"]\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(epochs, history[\"train_loss\"], label=\"train_loss\")\n",
    "    plt.plot(epochs, history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{title} - Loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"loss_curves.png\"), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(epochs, np.array(history[\"train_acc\"]) * 100, label=\"train_acc\")\n",
    "    plt.plot(epochs, np.array(history[\"val_acc\"]) * 100, label=\"val_acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.title(f\"{title} - Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"acc_curves.png\"), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, history[\"lr_backbone\"], label=\"lr_backbone\")\n",
    "    plt.plot(epochs, history[\"lr_lora_head\"], label=\"lr_lora/head\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"LR\")\n",
    "    plt.title(f\"{title} - LR schedule\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"lr_schedule.png\"), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 9. EVALUATION (TEST): METRICS + FIGURES + TSNE\n",
    "# ==========================================\n",
    "def unwrap_timm_backbone(model: nn.Module) -> nn.Module:\n",
    "    base = model\n",
    "    # robust unwrap (PEFT -> wrapper -> timm)\n",
    "    for _ in range(5):\n",
    "        if hasattr(base, \"base_model\"):\n",
    "            base = base.base_model\n",
    "            continue\n",
    "        if hasattr(base, \"model\"):\n",
    "            base = base.model\n",
    "            continue\n",
    "        break\n",
    "    return base\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_on_loader(model: nn.Module, loader: DataLoader, class_names: List[str]) -> Dict:\n",
    "    model.eval()\n",
    "    all_y, all_pred, all_probs, all_logits = [], [], [], []\n",
    "\n",
    "    for x, y in tqdm(loader, desc=\"Test eval\", leave=False):\n",
    "        x = x.to(CONFIG[\"device\"], non_blocking=True)\n",
    "        y = y.to(CONFIG[\"device\"], non_blocking=True)\n",
    "\n",
    "        with torch.autocast(device_type=CONFIG[\"device\"].type, enabled=CONFIG[\"amp_enabled\"]):\n",
    "            logits = forward_logits(model, x)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "        pred = probs.argmax(dim=1)\n",
    "\n",
    "        all_y.append(y.detach().cpu().numpy())\n",
    "        all_pred.append(pred.detach().cpu().numpy())\n",
    "        all_probs.append(probs.detach().cpu().numpy())\n",
    "        all_logits.append(logits.detach().cpu())\n",
    "\n",
    "    y_np = np.concatenate(all_y)\n",
    "    p_np = np.concatenate(all_pred)\n",
    "    probs_np = np.concatenate(all_probs)\n",
    "    logits_t = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    acc = float((p_np == y_np).mean())\n",
    "    macro_f1 = float(f1_score(y_np, p_np, average=\"macro\"))\n",
    "\n",
    "    macro_auc = None\n",
    "    try:\n",
    "        y_onehot = np.eye(len(class_names))[y_np]\n",
    "        macro_auc = float(roc_auc_score(y_onehot, probs_np, average=\"macro\", multi_class=\"ovr\"))\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not compute macro-AUC: {e}\")\n",
    "\n",
    "    ece = compute_ece(probs_np, y_np, n_bins=15)\n",
    "    nll = compute_nll(probs_np, y_np)\n",
    "    brier = compute_brier(probs_np, y_np, num_classes=len(class_names))\n",
    "\n",
    "    return {\n",
    "        \"labels\": y_np,\n",
    "        \"preds\": p_np,\n",
    "        \"probs\": probs_np,\n",
    "        \"logits\": logits_t,\n",
    "        \"acc\": acc,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"macro_auc\": macro_auc,\n",
    "        \"ece\": ece,\n",
    "        \"nll\": nll,\n",
    "        \"brier\": brier,\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_tsne_stratified(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    class_names: List[str],\n",
    "    title: str,\n",
    "    save_path: str,\n",
    "    samples_per_class: int = 200,\n",
    "):\n",
    "    backbone = unwrap_timm_backbone(model)\n",
    "    if not hasattr(backbone, \"forward_features\"):\n",
    "        print(\"[WARN] No forward_features(); skipping t-SNE.\")\n",
    "        return\n",
    "\n",
    "    model.eval()\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    feats_by_class = {i: [] for i in range(num_classes)}\n",
    "    labels_by_class = {i: [] for i in range(num_classes)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc=\"t-SNE stratified feats\", leave=False):\n",
    "            x = x.to(CONFIG[\"device\"], non_blocking=True)\n",
    "\n",
    "            with torch.autocast(device_type=CONFIG[\"device\"].type, enabled=CONFIG[\"amp_enabled\"]):\n",
    "                f = backbone.forward_features(x)\n",
    "            if f.ndim == 3:\n",
    "                f = f[:, 0]  # CLS token\n",
    "\n",
    "            f = f.detach().cpu().numpy()\n",
    "            y = y.numpy()\n",
    "\n",
    "            for i in range(len(y)):\n",
    "                c = int(y[i])\n",
    "                if len(feats_by_class[c]) < samples_per_class:\n",
    "                    feats_by_class[c].append(f[i])\n",
    "                    labels_by_class[c].append(c)\n",
    "\n",
    "            if all(len(feats_by_class[c]) >= samples_per_class for c in range(num_classes)):\n",
    "                break\n",
    "\n",
    "    X_list, y_list = [], []\n",
    "    for c in range(num_classes):\n",
    "        X_list.extend(feats_by_class[c])\n",
    "        y_list.extend(labels_by_class[c])\n",
    "\n",
    "    if len(X_list) < 30:\n",
    "        print(\"[WARN] Not enough samples for t-SNE.\")\n",
    "        return\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    print(f\"[INFO] t-SNE using {len(X)} samples ({samples_per_class} per class x {num_classes} classes).\")\n",
    "\n",
    "    idx = np.random.permutation(len(X))\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "\n",
    "    print(\"[INFO] Running t-SNE ...\")\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        random_state=CONFIG[\"seed\"],\n",
    "        perplexity=min(30, len(X) - 1),\n",
    "    )\n",
    "    Z = tsne.fit_transform(X)\n",
    "\n",
    "    palette = sns.color_palette(\"viridis\", num_classes)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(\n",
    "        x=Z[:, 0], y=Z[:, 1],\n",
    "        hue=[class_names[i] for i in y],\n",
    "        hue_order=class_names,\n",
    "        palette=palette,\n",
    "        alpha=0.85,\n",
    "        s=35\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.legend(title=\"Class\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 10. INFERENCE BENCHMARK (LATENCY/THROUGHPUT + VRAM)\n",
    "# ==========================================\n",
    "def maybe_merge_lora_for_timing(model: nn.Module) -> nn.Module:\n",
    "    if not CONFIG[\"bench_merge_lora\"]:\n",
    "        return model\n",
    "    if hasattr(model, \"merge_and_unload\"):\n",
    "        try:\n",
    "            merged = model.merge_and_unload()\n",
    "            print(\"[BENCH] LoRA merged (merge_and_unload).\")\n",
    "            return merged.to(CONFIG[\"device\"])\n",
    "        except Exception as e:\n",
    "            print(f\"[BENCH] merge_and_unload failed, benchmarking unmerged LoRA. Reason: {e}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def benchmark_inference(model: nn.Module, sample: torch.Tensor, batch_size: int) -> Dict:\n",
    "    model.eval()\n",
    "\n",
    "    x = sample[:batch_size].contiguous()\n",
    "    x = x.to(CONFIG[\"device\"], non_blocking=True)\n",
    "\n",
    "    if CONFIG[\"device\"].type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    for _ in range(CONFIG[\"bench_warmup_iters\"]):\n",
    "        with torch.autocast(device_type=CONFIG[\"device\"].type, enabled=CONFIG[\"amp_enabled\"]):\n",
    "            _ = forward_logits(model, x)\n",
    "    if CONFIG[\"device\"].type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    times_ms = []\n",
    "    for _ in range(CONFIG[\"bench_timed_iters\"]):\n",
    "        t0 = time.perf_counter()\n",
    "        with torch.autocast(device_type=CONFIG[\"device\"].type, enabled=CONFIG[\"amp_enabled\"]):\n",
    "            _ = forward_logits(model, x)\n",
    "        if CONFIG[\"device\"].type == \"cuda\":\n",
    "            torch.cuda.synchronize()\n",
    "        t1 = time.perf_counter()\n",
    "        times_ms.append((t1 - t0) * 1000.0)\n",
    "\n",
    "    times_ms = np.array(times_ms, dtype=np.float64)\n",
    "    mean_ms = float(times_ms.mean())\n",
    "    std_ms = float(times_ms.std())\n",
    "\n",
    "    ms_per_img = mean_ms / batch_size\n",
    "    imgs_per_s = 1000.0 / ms_per_img\n",
    "\n",
    "    peak_vram_gb = 0.0\n",
    "    if CONFIG[\"device\"].type == \"cuda\":\n",
    "        peak_vram_gb = torch.cuda.max_memory_allocated() / (1024**3)\n",
    "\n",
    "    return {\n",
    "        \"batch\": batch_size,\n",
    "        \"mean_batch_ms\": mean_ms,\n",
    "        \"std_batch_ms\": std_ms,\n",
    "        \"ms_per_img\": float(ms_per_img),\n",
    "        \"imgs_per_s\": float(imgs_per_s),\n",
    "        \"peak_vram_gb\": float(peak_vram_gb),\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 11. MAIN: RUN BOTH DATASETS\n",
    "# ==========================================\n",
    "def main():\n",
    "    mode_tag, mode_title = get_mode_strings()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(f\"DeiT + LoRA OCT Pipeline | {mode_title}\")\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"[ENV] torch={torch.__version__} cuda={torch.cuda.is_available()} device={CONFIG['device']}\")\n",
    "    print(f\"[CFG] model={CONFIG['model_name']} img_size={CONFIG['img_size']} batch={CONFIG['batch_size']} amp={CONFIG['amp_enabled']}\")\n",
    "    print(f\"[CFG] mode={mode_tag} | base_lr={CONFIG['lr']} | backbone_lr(unfrozen)={CONFIG['lr']*0.1}\")\n",
    "    print(\"=\" * 90)\n",
    "\n",
    "    for ds_name in RUN_DATASETS:\n",
    "        if ds_name not in DATASET_CONFIGS:\n",
    "            print(f\"[SKIP] Unknown dataset '{ds_name}'\")\n",
    "            continue\n",
    "\n",
    "        train_loader, val_loader, test_loader, class_names = build_dataloaders(ds_name, DATASET_CONFIGS[ds_name])\n",
    "        run_paths = make_run_paths(ds_name, num_classes=len(class_names))\n",
    "\n",
    "        model, history, total_train_time, param_stats, adapter_bytes = train_engine(\n",
    "            ds_name, train_loader, val_loader, class_names, run_paths\n",
    "        )\n",
    "\n",
    "        plot_training_curves(history, title=f\"{ds_name} | {mode_title}\", out_dir=run_paths.out_dir)\n",
    "\n",
    "        test_metrics = evaluate_on_loader(model, test_loader, class_names)\n",
    "\n",
    "        # Temperature scaling\n",
    "        T = None\n",
    "        test_metrics_cal = None\n",
    "        if CONFIG[\"use_temperature_scaling\"]:\n",
    "            ts_model = fit_temperature_on_val(model, val_loader)\n",
    "            logits = test_metrics[\"logits\"].to(CONFIG[\"device\"])\n",
    "            with torch.no_grad():\n",
    "                scaled_logits = ts_model(logits)\n",
    "                probs_cal = torch.softmax(scaled_logits, dim=1).detach().cpu().numpy()\n",
    "\n",
    "            y = test_metrics[\"labels\"]\n",
    "            ece = compute_ece(probs_cal, y, n_bins=15)\n",
    "            nll = compute_nll(probs_cal, y)\n",
    "            brier = compute_brier(probs_cal, y, num_classes=len(class_names))\n",
    "            T = ts_model.get_T()\n",
    "            test_metrics_cal = {\"ece\": ece, \"nll\": nll, \"brier\": brier}\n",
    "\n",
    "            plot_reliability_diagram(\n",
    "                probs_cal, y, n_bins=15,\n",
    "                title=f\"{ds_name} Reliability (Temp-scaled, T={T:.3f})\",\n",
    "                save_path=os.path.join(run_paths.out_dir, \"reliability_temp_scaled.png\")\n",
    "            )\n",
    "\n",
    "        # Reports + figures\n",
    "        y = test_metrics[\"labels\"]\n",
    "        p = test_metrics[\"preds\"]\n",
    "        probs = test_metrics[\"probs\"]\n",
    "\n",
    "        rep = classification_report(y, p, target_names=class_names, digits=4, zero_division=0)\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(f\"[{ds_name}] TEST classification report (uncalibrated)\")\n",
    "        print(\"-\" * 80)\n",
    "        print(rep)\n",
    "\n",
    "        cm = confusion_matrix(y, p)\n",
    "        plot_confusion(cm, class_names, f\"{ds_name} Confusion (normalized)\", os.path.join(run_paths.out_dir, \"confusion.png\"))\n",
    "        plot_classification_report_heatmap(rep, f\"{ds_name} Class report heatmap\", os.path.join(run_paths.out_dir, \"cls_report_heatmap.png\"))\n",
    "        plot_sens_spec(cm, class_names, f\"{ds_name} Sensitivity/Specificity\", os.path.join(run_paths.out_dir, \"sens_spec.png\"))\n",
    "        plot_roc_curves(y, probs, class_names, f\"{ds_name} ROC (OVR)\", os.path.join(run_paths.out_dir, \"roc.png\"))\n",
    "        plot_reliability_diagram(\n",
    "            probs, y, n_bins=15,\n",
    "            title=f\"{ds_name} Reliability (uncalibrated)\",\n",
    "            save_path=os.path.join(run_paths.out_dir, \"reliability_uncalibrated.png\")\n",
    "        )\n",
    "        plot_tsne_stratified(\n",
    "            model,\n",
    "            test_loader,\n",
    "            class_names,\n",
    "            title=f\"{ds_name} t-SNE (CLS features, stratified)\",\n",
    "            save_path=os.path.join(run_paths.out_dir, \"tsne_stratified.png\"),\n",
    "            samples_per_class=200\n",
    "        )\n",
    "\n",
    "        # Benchmark\n",
    "        x0, _ = next(iter(test_loader))\n",
    "        model_for_bench = maybe_merge_lora_for_timing(model)\n",
    "        bench_lat = benchmark_inference(model_for_bench, x0, CONFIG[\"bench_latency_batch\"])\n",
    "        bench_thr = benchmark_inference(model_for_bench, x0, min(CONFIG[\"bench_throughput_batch\"], x0.size(0)))\n",
    "\n",
    "        # Summary\n",
    "        total_p, trainable_p, trainable_pct = param_stats\n",
    "        best_val_loss = float(np.min(history[\"val_loss\"]))\n",
    "        best_val_f1 = float(np.max(history[\"val_macro_f1\"]))\n",
    "        mean_epoch_time = float(np.mean(history[\"epoch_time_sec\"]))\n",
    "        peak_train_vram = float(np.max(history[\"train_peak_vram_gb\"]))\n",
    "\n",
    "        summary = {\n",
    "            \"dataset\": ds_name,\n",
    "            \"classes\": class_names,\n",
    "            \"model\": CONFIG[\"model_name\"],\n",
    "            \"mode\": mode_title,\n",
    "            \"freeze_backbone\": bool(CONFIG[\"freeze_backbone\"]),\n",
    "            \"lora\": {\n",
    "                \"r\": CONFIG[\"lora_r\"],\n",
    "                \"alpha\": CONFIG[\"lora_alpha\"],\n",
    "                \"dropout\": CONFIG[\"lora_dropout\"],\n",
    "                \"merged_for_timing\": bool(CONFIG[\"bench_merge_lora\"]),\n",
    "            },\n",
    "            \"params\": {\n",
    "                \"total\": int(total_p),\n",
    "                \"trainable\": int(trainable_p),\n",
    "                \"trainable_pct\": float(trainable_pct),\n",
    "            },\n",
    "            \"optimizer\": {\n",
    "                \"base_lr\": float(CONFIG[\"lr\"]),\n",
    "                \"backbone_lr_factor_if_unfrozen\": 0.1,\n",
    "                \"last_lr_backbone\": float(history[\"lr_backbone\"][-1]),\n",
    "                \"last_lr_lora_head\": float(history[\"lr_lora_head\"][-1]),\n",
    "            },\n",
    "            \"storage\": {\n",
    "                \"adapter_only_bytes\": int(adapter_bytes),\n",
    "                \"adapter_only_mb\": float(adapter_bytes / (1024**2)) if adapter_bytes else None,\n",
    "            },\n",
    "            \"training\": {\n",
    "                \"epochs_ran\": int(len(history[\"epoch\"])),\n",
    "                \"best_val_loss\": best_val_loss,\n",
    "                \"best_val_macro_f1\": best_val_f1,\n",
    "                \"total_train_time_sec\": float(total_train_time),\n",
    "                \"mean_epoch_time_sec\": mean_epoch_time,\n",
    "                \"peak_train_vram_gb\": peak_train_vram,\n",
    "            },\n",
    "            \"test_uncalibrated\": {\n",
    "                \"acc\": float(test_metrics[\"acc\"]),\n",
    "                \"macro_f1\": float(test_metrics[\"macro_f1\"]),\n",
    "                \"macro_auc\": test_metrics[\"macro_auc\"],\n",
    "                \"ece\": float(test_metrics[\"ece\"]),\n",
    "                \"nll\": float(test_metrics[\"nll\"]),\n",
    "                \"brier\": float(test_metrics[\"brier\"]),\n",
    "            },\n",
    "            \"test_temp_scaled\": {\n",
    "                \"enabled\": bool(CONFIG[\"use_temperature_scaling\"]),\n",
    "                \"T\": T,\n",
    "                **(test_metrics_cal if test_metrics_cal is not None else {}),\n",
    "            },\n",
    "            \"inference_benchmark\": {\n",
    "                \"latency_batch1\": bench_lat,\n",
    "                \"throughput_batchN\": bench_thr,\n",
    "            }\n",
    "        }\n",
    "\n",
    "        with open(run_paths.summary_json, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"[{ds_name}] MODE: {mode_title}\")\n",
    "        print(f\"[{ds_name}] TEST summary (uncalibrated): \"\n",
    "              f\"Acc={test_metrics['acc']*100:.2f}% MacroF1={test_metrics['macro_f1']*100:.2f}% \"\n",
    "              f\"ECE={test_metrics['ece']:.4f} NLL={test_metrics['nll']:.4f} Brier={test_metrics['brier']:.4f}\")\n",
    "        if test_metrics[\"macro_auc\"] is not None:\n",
    "            print(f\"[{ds_name}] Macro-AUC={test_metrics['macro_auc']:.4f}\")\n",
    "        if test_metrics_cal is not None:\n",
    "            print(f\"[{ds_name}] TEMP-SCALED (T={T:.3f}): ECE={test_metrics_cal['ece']:.4f} \"\n",
    "                  f\"NLL={test_metrics_cal['nll']:.4f} Brier={test_metrics_cal['brier']:.4f}\")\n",
    "        print(f\"[{ds_name}] Params trainable: {trainable_p:,} ({trainable_pct:.3f}%)\")\n",
    "        if adapter_bytes:\n",
    "            print(f\"[{ds_name}] Adapter-only size: {adapter_bytes/(1024**2):.2f} MB\")\n",
    "        print(f\"[{ds_name}] Inference latency (B=1): {bench_lat['ms_per_img']:.3f} ms/img \"\n",
    "              f\"({bench_lat['imgs_per_s']:.1f} imgs/s), peakVRAM={bench_lat['peak_vram_gb']:.2f}GB\")\n",
    "        print(f\"[{ds_name}] Inference throughput (B={bench_thr['batch']}): {bench_thr['imgs_per_s']:.1f} imgs/s, \"\n",
    "              f\"peakVRAM={bench_thr['peak_vram_gb']:.2f}GB\")\n",
    "        print(f\"[{ds_name}] Outputs saved in: {run_paths.out_dir}\")\n",
    "        print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "        # ---- CLEANUP (after finishing one dataset) ----\n",
    "        del model\n",
    "        del model_for_bench\n",
    "        del train_loader, val_loader, test_loader\n",
    "        del history, test_metrics, cm, rep\n",
    "        del x0\n",
    "\n",
    "        if \"ts_model\" in locals():\n",
    "            del ts_model\n",
    "        if \"logits\" in locals():\n",
    "            del logits\n",
    "        if \"scaled_logits\" in locals():\n",
    "            del scaled_logits\n",
    "\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.ipc_collect()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
