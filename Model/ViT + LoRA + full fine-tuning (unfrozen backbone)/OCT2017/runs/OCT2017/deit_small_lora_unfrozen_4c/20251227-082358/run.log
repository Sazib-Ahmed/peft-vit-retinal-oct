
=== DATASET RUN START: OCT2017 ===

[DATA] Split/Class counts:
class    CNV   DME  DRUSEN  NORMAL  TOTAL
split                                    
test     250   250     250     250   1000
train  28285  9819    7000   45054  90158
val     3142  1091     777    5006  10016
[DATA] Train imbalance: min=7000, max=45054, ratio=6.44
[RAM] Caching split='train' images=90158 as uint8 tensors. Estimated RAM ~ 12.64 GB
[RAM] Cached 90158 images for split='train'
[RAM] Caching split='val' images=10016 as uint8 tensors. Estimated RAM ~ 1.40 GB
[RAM] Cached 10016 images for split='val'
[RAM] Caching split='test' images=1000 as uint8 tensors. Estimated RAM ~ 0.14 GB
[RAM] Cached 1000 images for split='test'
[IMB] Train class counts: [28285, 9819, 7000, 45054]
[IMB] Class-Balanced weights (mean~1): [0.7512, 1.1301, 1.404, 0.7147]
[IMB] Sampler disabled. min=7000 max=45054 ratio=6.44

[DATASET] OCT2017
 - root: D:\AIUB\DSP\Code\Datasets\ZhangLabData\OCT2017_CLEAN_SHAONLY
 - pad_to_square: True
 - cache_in_ram: True
 - classes (4): ['CNV', 'DME', 'DRUSEN', 'NORMAL']
 - split sizes: train=90158 val=10016 test=1000

[MODEL] Creating deit_small_distilled_patch16_224 + Manual LoRA | backbone=UNFROZEN (LoRA + full FT)
[PARAMS] total=21,816,968 trainable=21,816,968 (100.0000%)
[WARN] save_adapter_only=True but backbone is UNFROZEN. Adapter-only file will NOT reproduce the full trained model. Use best_model.pth for deployment/repro.
[IMB] Train class counts: [28285, 9819, 7000, 45054]
[IMB] Class-Balanced weights (mean~1): [0.7512, 1.1301, 1.404, 0.7147]
[IMB] Sampler disabled. min=7000 max=45054 ratio=6.44
[OPT] AdamW param-groups | lr_backbone=5.00e-05 lr_lora+head=5.00e-04 (backbone_lr_mult=0.1)
[OCT2017] Epoch 001/100 | lr_backbone=1.00e-05 lr_lora+head=1.00e-04 | train_loss=0.6450 train_acc=90.56% | val_loss=0.5263 val_acc=95.79% val_macroF1=92.74% | ep_time=167.4s peakVRAM=2.62GB
[ES] New best val_loss=0.526292 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 002/100 | lr_backbone=1.50e-05 lr_lora+head=1.50e-04 | train_loss=0.5650 train_acc=93.89% | val_loss=0.5116 val_acc=96.17% val_macroF1=93.24% | ep_time=162.5s peakVRAM=2.62GB
[ES] New best val_loss=0.511568 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 003/100 | lr_backbone=2.00e-05 lr_lora+head=2.00e-04 | train_loss=0.5528 train_acc=94.32% | val_loss=0.5025 val_acc=96.84% val_macroF1=94.46% | ep_time=161.0s peakVRAM=2.62GB
[ES] New best val_loss=0.502469 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 004/100 | lr_backbone=2.50e-05 lr_lora+head=2.50e-04 | train_loss=0.5460 train_acc=94.75% | val_loss=0.4959 val_acc=97.04% val_macroF1=94.72% | ep_time=161.1s peakVRAM=2.62GB
[ES] New best val_loss=0.495947 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 005/100 | lr_backbone=3.00e-05 lr_lora+head=3.00e-04 | train_loss=0.5486 train_acc=94.52% | val_loss=0.4962 val_acc=96.99% val_macroF1=94.67% | ep_time=160.0s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 006/100 | lr_backbone=3.50e-05 lr_lora+head=3.50e-04 | train_loss=0.5427 train_acc=94.81% | val_loss=0.4939 val_acc=97.26% val_macroF1=94.99% | ep_time=160.6s peakVRAM=2.62GB
[ES] New best val_loss=0.493857 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 007/100 | lr_backbone=4.00e-05 lr_lora+head=4.00e-04 | train_loss=0.5430 train_acc=94.80% | val_loss=0.5007 val_acc=96.90% val_macroF1=94.59% | ep_time=161.5s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 008/100 | lr_backbone=4.50e-05 lr_lora+head=4.50e-04 | train_loss=0.5439 train_acc=94.70% | val_loss=0.4973 val_acc=97.02% val_macroF1=94.67% | ep_time=162.9s peakVRAM=2.62GB
[ES] No improve 2/10
[OCT2017] Epoch 009/100 | lr_backbone=5.00e-05 lr_lora+head=5.00e-04 | train_loss=0.5449 train_acc=94.62% | val_loss=0.5006 val_acc=96.97% val_macroF1=94.82% | ep_time=161.3s peakVRAM=2.62GB
[ES] No improve 3/10
[OCT2017] Epoch 010/100 | lr_backbone=5.00e-05 lr_lora+head=5.00e-04 | train_loss=0.5451 train_acc=94.59% | val_loss=0.4986 val_acc=96.98% val_macroF1=94.60% | ep_time=160.9s peakVRAM=2.62GB
[ES] No improve 4/10
[OCT2017] Epoch 011/100 | lr_backbone=5.00e-05 lr_lora+head=5.00e-04 | train_loss=0.5399 train_acc=94.84% | val_loss=0.5192 val_acc=96.36% val_macroF1=93.60% | ep_time=161.5s peakVRAM=2.62GB
[ES] No improve 5/10
[OCT2017] Epoch 012/100 | lr_backbone=4.99e-05 lr_lora+head=4.99e-04 | train_loss=0.5339 train_acc=95.13% | val_loss=0.5032 val_acc=96.65% val_macroF1=94.16% | ep_time=161.6s peakVRAM=2.62GB
[ES] No improve 6/10
[OCT2017] Epoch 013/100 | lr_backbone=4.99e-05 lr_lora+head=4.99e-04 | train_loss=0.5294 train_acc=95.36% | val_loss=0.4845 val_acc=97.60% val_macroF1=95.62% | ep_time=160.9s peakVRAM=2.62GB
[ES] New best val_loss=0.484518 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 014/100 | lr_backbone=4.98e-05 lr_lora+head=4.98e-04 | train_loss=0.5295 train_acc=95.36% | val_loss=0.4934 val_acc=97.22% val_macroF1=95.15% | ep_time=160.4s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 015/100 | lr_backbone=4.96e-05 lr_lora+head=4.96e-04 | train_loss=0.5235 train_acc=95.63% | val_loss=0.4875 val_acc=97.50% val_macroF1=95.48% | ep_time=160.4s peakVRAM=2.62GB
[ES] No improve 2/10
[OCT2017] Epoch 016/100 | lr_backbone=4.95e-05 lr_lora+head=4.95e-04 | train_loss=0.5205 train_acc=95.69% | val_loss=0.4870 val_acc=97.59% val_macroF1=95.80% | ep_time=160.6s peakVRAM=2.62GB
[ES] No improve 3/10
[OCT2017] Epoch 017/100 | lr_backbone=4.93e-05 lr_lora+head=4.93e-04 | train_loss=0.5164 train_acc=95.90% | val_loss=0.4839 val_acc=97.76% val_macroF1=95.97% | ep_time=161.0s peakVRAM=2.62GB
[ES] New best val_loss=0.483917 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 018/100 | lr_backbone=4.90e-05 lr_lora+head=4.90e-04 | train_loss=0.5150 train_acc=95.93% | val_loss=0.4826 val_acc=97.79% val_macroF1=96.05% | ep_time=159.6s peakVRAM=2.62GB
[ES] New best val_loss=0.482604 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 019/100 | lr_backbone=4.88e-05 lr_lora+head=4.88e-04 | train_loss=0.5107 train_acc=96.18% | val_loss=0.4782 val_acc=98.03% val_macroF1=96.42% | ep_time=159.8s peakVRAM=2.62GB
[ES] New best val_loss=0.478188 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 020/100 | lr_backbone=4.85e-05 lr_lora+head=4.85e-04 | train_loss=0.5108 train_acc=96.13% | val_loss=0.4771 val_acc=98.01% val_macroF1=96.29% | ep_time=159.9s peakVRAM=2.62GB
[ES] New best val_loss=0.477091 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 021/100 | lr_backbone=4.82e-05 lr_lora+head=4.82e-04 | train_loss=0.5090 train_acc=96.25% | val_loss=0.4834 val_acc=97.72% val_macroF1=95.81% | ep_time=160.3s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 022/100 | lr_backbone=4.78e-05 lr_lora+head=4.78e-04 | train_loss=0.5131 train_acc=95.94% | val_loss=0.4770 val_acc=98.13% val_macroF1=96.58% | ep_time=160.0s peakVRAM=2.62GB
[ES] New best val_loss=0.476977 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 023/100 | lr_backbone=4.75e-05 lr_lora+head=4.75e-04 | train_loss=0.5036 train_acc=96.47% | val_loss=0.4754 val_acc=98.24% val_macroF1=96.84% | ep_time=160.4s peakVRAM=2.62GB
[ES] New best val_loss=0.475403 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 024/100 | lr_backbone=4.71e-05 lr_lora+head=4.71e-04 | train_loss=0.5065 train_acc=96.29% | val_loss=0.4836 val_acc=97.75% val_macroF1=96.04% | ep_time=161.6s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 025/100 | lr_backbone=4.67e-05 lr_lora+head=4.67e-04 | train_loss=0.5032 train_acc=96.43% | val_loss=0.4838 val_acc=97.76% val_macroF1=96.05% | ep_time=161.4s peakVRAM=2.62GB
[ES] No improve 2/10
[OCT2017] Epoch 026/100 | lr_backbone=4.62e-05 lr_lora+head=4.62e-04 | train_loss=0.5023 train_acc=96.49% | val_loss=0.4799 val_acc=97.98% val_macroF1=96.40% | ep_time=162.8s peakVRAM=2.62GB
[ES] No improve 3/10
[OCT2017] Epoch 027/100 | lr_backbone=4.57e-05 lr_lora+head=4.57e-04 | train_loss=0.5008 train_acc=96.50% | val_loss=0.4857 val_acc=97.74% val_macroF1=95.96% | ep_time=161.2s peakVRAM=2.62GB
[ES] No improve 4/10
[OCT2017] Epoch 028/100 | lr_backbone=4.52e-05 lr_lora+head=4.52e-04 | train_loss=0.4998 train_acc=96.57% | val_loss=0.4821 val_acc=97.82% val_macroF1=96.15% | ep_time=161.5s peakVRAM=2.62GB
[ES] No improve 5/10
[OCT2017] Epoch 029/100 | lr_backbone=4.47e-05 lr_lora+head=4.47e-04 | train_loss=0.4963 train_acc=96.72% | val_loss=0.4740 val_acc=98.26% val_macroF1=96.90% | ep_time=160.8s peakVRAM=2.62GB
[ES] New best val_loss=0.474005 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 030/100 | lr_backbone=4.42e-05 lr_lora+head=4.42e-04 | train_loss=0.4969 train_acc=96.64% | val_loss=0.4743 val_acc=98.22% val_macroF1=96.73% | ep_time=160.5s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 031/100 | lr_backbone=4.36e-05 lr_lora+head=4.36e-04 | train_loss=0.4934 train_acc=96.83% | val_loss=0.4775 val_acc=98.14% val_macroF1=96.55% | ep_time=161.3s peakVRAM=2.62GB
[ES] No improve 2/10
[OCT2017] Epoch 032/100 | lr_backbone=4.30e-05 lr_lora+head=4.30e-04 | train_loss=0.4895 train_acc=96.99% | val_loss=0.4719 val_acc=98.42% val_macroF1=97.20% | ep_time=161.9s peakVRAM=2.62GB
[ES] New best val_loss=0.471914 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 033/100 | lr_backbone=4.24e-05 lr_lora+head=4.24e-04 | train_loss=0.4938 train_acc=96.87% | val_loss=0.4718 val_acc=98.29% val_macroF1=96.83% | ep_time=159.6s peakVRAM=2.62GB
[ES] New best val_loss=0.471807 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 034/100 | lr_backbone=4.17e-05 lr_lora+head=4.17e-04 | train_loss=0.4907 train_acc=97.02% | val_loss=0.4715 val_acc=98.35% val_macroF1=96.95% | ep_time=160.9s peakVRAM=2.62GB
[ES] New best val_loss=0.471477 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 035/100 | lr_backbone=4.11e-05 lr_lora+head=4.11e-04 | train_loss=0.4846 train_acc=97.22% | val_loss=0.4750 val_acc=98.31% val_macroF1=96.92% | ep_time=162.1s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 036/100 | lr_backbone=4.04e-05 lr_lora+head=4.04e-04 | train_loss=0.4837 train_acc=97.31% | val_loss=0.4717 val_acc=98.41% val_macroF1=97.08% | ep_time=160.3s peakVRAM=2.62GB
[ES] No improve 2/10
[OCT2017] Epoch 037/100 | lr_backbone=3.97e-05 lr_lora+head=3.97e-04 | train_loss=0.4874 train_acc=97.08% | val_loss=0.4734 val_acc=98.34% val_macroF1=96.97% | ep_time=159.7s peakVRAM=2.62GB
[ES] No improve 3/10
[OCT2017] Epoch 038/100 | lr_backbone=3.90e-05 lr_lora+head=3.90e-04 | train_loss=0.4839 train_acc=97.26% | val_loss=0.4733 val_acc=98.33% val_macroF1=96.97% | ep_time=160.4s peakVRAM=2.62GB
[ES] No improve 4/10
[OCT2017] Epoch 039/100 | lr_backbone=3.82e-05 lr_lora+head=3.82e-04 | train_loss=0.4863 train_acc=97.13% | val_loss=0.4722 val_acc=98.33% val_macroF1=96.94% | ep_time=160.3s peakVRAM=2.62GB
[ES] No improve 5/10
[OCT2017] Epoch 040/100 | lr_backbone=3.75e-05 lr_lora+head=3.75e-04 | train_loss=0.4836 train_acc=97.19% | val_loss=0.4702 val_acc=98.42% val_macroF1=97.14% | ep_time=159.7s peakVRAM=2.62GB
[ES] New best val_loss=0.470177 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 041/100 | lr_backbone=3.67e-05 lr_lora+head=3.67e-04 | train_loss=0.4838 train_acc=97.23% | val_loss=0.4694 val_acc=98.47% val_macroF1=97.17% | ep_time=158.5s peakVRAM=2.62GB
[ES] New best val_loss=0.469417 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 042/100 | lr_backbone=3.60e-05 lr_lora+head=3.60e-04 | train_loss=0.4787 train_acc=97.49% | val_loss=0.4693 val_acc=98.48% val_macroF1=97.21% | ep_time=158.7s peakVRAM=2.62GB
[ES] New best val_loss=0.469251 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 043/100 | lr_backbone=3.52e-05 lr_lora+head=3.52e-04 | train_loss=0.4809 train_acc=97.35% | val_loss=0.4701 val_acc=98.44% val_macroF1=97.15% | ep_time=158.2s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 044/100 | lr_backbone=3.44e-05 lr_lora+head=3.44e-04 | train_loss=0.4776 train_acc=97.53% | val_loss=0.4728 val_acc=98.45% val_macroF1=97.17% | ep_time=158.2s peakVRAM=2.62GB
[ES] No improve 2/10
[OCT2017] Epoch 045/100 | lr_backbone=3.36e-05 lr_lora+head=3.36e-04 | train_loss=0.4783 train_acc=97.49% | val_loss=0.4735 val_acc=98.29% val_macroF1=96.87% | ep_time=158.2s peakVRAM=2.62GB
[ES] No improve 3/10
[OCT2017] Epoch 046/100 | lr_backbone=3.27e-05 lr_lora+head=3.27e-04 | train_loss=0.4771 train_acc=97.55% | val_loss=0.4727 val_acc=98.31% val_macroF1=96.91% | ep_time=158.4s peakVRAM=2.62GB
[ES] No improve 4/10
[OCT2017] Epoch 047/100 | lr_backbone=3.19e-05 lr_lora+head=3.19e-04 | train_loss=0.4787 train_acc=97.41% | val_loss=0.4747 val_acc=98.31% val_macroF1=96.92% | ep_time=162.2s peakVRAM=2.62GB
[ES] No improve 5/10
[OCT2017] Epoch 048/100 | lr_backbone=3.10e-05 lr_lora+head=3.10e-04 | train_loss=0.4701 train_acc=97.83% | val_loss=0.4682 val_acc=98.59% val_macroF1=97.40% | ep_time=161.6s peakVRAM=2.62GB
[ES] New best val_loss=0.468190 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 049/100 | lr_backbone=3.02e-05 lr_lora+head=3.02e-04 | train_loss=0.4733 train_acc=97.64% | val_loss=0.4696 val_acc=98.50% val_macroF1=97.19% | ep_time=161.7s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 050/100 | lr_backbone=2.93e-05 lr_lora+head=2.93e-04 | train_loss=0.4718 train_acc=97.74% | val_loss=0.4676 val_acc=98.66% val_macroF1=97.58% | ep_time=161.0s peakVRAM=2.62GB
[ES] New best val_loss=0.467568 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 051/100 | lr_backbone=2.85e-05 lr_lora+head=2.85e-04 | train_loss=0.4700 train_acc=97.88% | val_loss=0.4703 val_acc=98.58% val_macroF1=97.42% | ep_time=161.0s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 052/100 | lr_backbone=2.76e-05 lr_lora+head=2.76e-04 | train_loss=0.4673 train_acc=97.94% | val_loss=0.4698 val_acc=98.58% val_macroF1=97.40% | ep_time=161.1s peakVRAM=2.62GB
[ES] No improve 2/10
[OCT2017] Epoch 053/100 | lr_backbone=2.67e-05 lr_lora+head=2.67e-04 | train_loss=0.4674 train_acc=97.96% | val_loss=0.4722 val_acc=98.47% val_macroF1=97.26% | ep_time=161.4s peakVRAM=2.62GB
[ES] No improve 3/10
[OCT2017] Epoch 054/100 | lr_backbone=2.59e-05 lr_lora+head=2.59e-04 | train_loss=0.4680 train_acc=97.90% | val_loss=0.4686 val_acc=98.72% val_macroF1=97.69% | ep_time=160.9s peakVRAM=2.62GB
[ES] No improve 4/10
[OCT2017] Epoch 055/100 | lr_backbone=2.50e-05 lr_lora+head=2.50e-04 | train_loss=0.4664 train_acc=97.94% | val_loss=0.4708 val_acc=98.51% val_macroF1=97.32% | ep_time=160.8s peakVRAM=2.62GB
[ES] No improve 5/10
[OCT2017] Epoch 056/100 | lr_backbone=2.41e-05 lr_lora+head=2.41e-04 | train_loss=0.4649 train_acc=98.00% | val_loss=0.4720 val_acc=98.52% val_macroF1=97.39% | ep_time=160.8s peakVRAM=2.62GB
[ES] No improve 6/10
[OCT2017] Epoch 057/100 | lr_backbone=2.33e-05 lr_lora+head=2.33e-04 | train_loss=0.4634 train_acc=98.14% | val_loss=0.4706 val_acc=98.59% val_macroF1=97.47% | ep_time=160.8s peakVRAM=2.62GB
[ES] No improve 7/10
[OCT2017] Epoch 058/100 | lr_backbone=2.24e-05 lr_lora+head=2.24e-04 | train_loss=0.4635 train_acc=98.12% | val_loss=0.4692 val_acc=98.60% val_macroF1=97.42% | ep_time=160.6s peakVRAM=2.62GB
[ES] No improve 8/10
[OCT2017] Epoch 059/100 | lr_backbone=2.15e-05 lr_lora+head=2.15e-04 | train_loss=0.4617 train_acc=98.18% | val_loss=0.4707 val_acc=98.57% val_macroF1=97.45% | ep_time=160.6s peakVRAM=2.62GB
[ES] No improve 9/10
[OCT2017] Epoch 060/100 | lr_backbone=2.07e-05 lr_lora+head=2.07e-04 | train_loss=0.4609 train_acc=98.22% | val_loss=0.4668 val_acc=98.77% val_macroF1=97.71% | ep_time=160.7s peakVRAM=2.62GB
[ES] New best val_loss=0.466804 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 061/100 | lr_backbone=1.98e-05 lr_lora+head=1.98e-04 | train_loss=0.4607 train_acc=98.25% | val_loss=0.4719 val_acc=98.60% val_macroF1=97.44% | ep_time=160.8s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 062/100 | lr_backbone=1.90e-05 lr_lora+head=1.90e-04 | train_loss=0.4601 train_acc=98.23% | val_loss=0.4679 val_acc=98.73% val_macroF1=97.70% | ep_time=160.8s peakVRAM=2.62GB
[ES] No improve 2/10
[OCT2017] Epoch 063/100 | lr_backbone=1.81e-05 lr_lora+head=1.81e-04 | train_loss=0.4614 train_acc=98.15% | val_loss=0.4699 val_acc=98.72% val_macroF1=97.70% | ep_time=159.5s peakVRAM=2.62GB
[ES] No improve 3/10
[OCT2017] Epoch 064/100 | lr_backbone=1.73e-05 lr_lora+head=1.73e-04 | train_loss=0.4574 train_acc=98.36% | val_loss=0.4675 val_acc=98.72% val_macroF1=97.66% | ep_time=157.6s peakVRAM=2.62GB
[ES] No improve 4/10
[OCT2017] Epoch 065/100 | lr_backbone=1.64e-05 lr_lora+head=1.64e-04 | train_loss=0.4573 train_acc=98.36% | val_loss=0.4666 val_acc=98.80% val_macroF1=97.87% | ep_time=157.7s peakVRAM=2.62GB
[ES] New best val_loss=0.466618 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 066/100 | lr_backbone=1.56e-05 lr_lora+head=1.56e-04 | train_loss=0.4575 train_acc=98.36% | val_loss=0.4688 val_acc=98.66% val_macroF1=97.53% | ep_time=157.7s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 067/100 | lr_backbone=1.48e-05 lr_lora+head=1.48e-04 | train_loss=0.4575 train_acc=98.31% | val_loss=0.4679 val_acc=98.69% val_macroF1=97.62% | ep_time=157.7s peakVRAM=2.62GB
[ES] No improve 2/10
[OCT2017] Epoch 068/100 | lr_backbone=1.40e-05 lr_lora+head=1.40e-04 | train_loss=0.4556 train_acc=98.40% | val_loss=0.4666 val_acc=98.74% val_macroF1=97.67% | ep_time=157.6s peakVRAM=2.62GB
[ES] New best val_loss=0.466574 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 069/100 | lr_backbone=1.33e-05 lr_lora+head=1.33e-04 | train_loss=0.4533 train_acc=98.53% | val_loss=0.4662 val_acc=98.79% val_macroF1=97.78% | ep_time=157.6s peakVRAM=2.62GB
[ES] New best val_loss=0.466172 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 070/100 | lr_backbone=1.25e-05 lr_lora+head=1.25e-04 | train_loss=0.4531 train_acc=98.56% | val_loss=0.4634 val_acc=98.89% val_macroF1=97.96% | ep_time=157.7s peakVRAM=2.62GB
[ES] New best val_loss=0.463439 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 071/100 | lr_backbone=1.18e-05 lr_lora+head=1.18e-04 | train_loss=0.4532 train_acc=98.53% | val_loss=0.4674 val_acc=98.77% val_macroF1=97.75% | ep_time=157.7s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 072/100 | lr_backbone=1.10e-05 lr_lora+head=1.10e-04 | train_loss=0.4511 train_acc=98.65% | val_loss=0.4666 val_acc=98.81% val_macroF1=97.84% | ep_time=157.6s peakVRAM=2.62GB
[ES] No improve 2/10
[OCT2017] Epoch 073/100 | lr_backbone=1.03e-05 lr_lora+head=1.03e-04 | train_loss=0.4510 train_acc=98.63% | val_loss=0.4634 val_acc=98.95% val_macroF1=98.08% | ep_time=157.6s peakVRAM=2.62GB
[ES] New best val_loss=0.463368 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 074/100 | lr_backbone=9.61e-06 lr_lora+head=9.61e-05 | train_loss=0.4522 train_acc=98.62% | val_loss=0.4657 val_acc=98.83% val_macroF1=97.85% | ep_time=157.6s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 075/100 | lr_backbone=8.93e-06 lr_lora+head=8.93e-05 | train_loss=0.4513 train_acc=98.63% | val_loss=0.4632 val_acc=98.91% val_macroF1=98.01% | ep_time=157.6s peakVRAM=2.62GB
[ES] New best val_loss=0.463163 -> saved runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358\best_model.pth
[OCT2017] Epoch 076/100 | lr_backbone=8.27e-06 lr_lora+head=8.27e-05 | train_loss=0.4469 train_acc=98.80% | val_loss=0.4651 val_acc=98.88% val_macroF1=97.97% | ep_time=157.6s peakVRAM=2.62GB
[ES] No improve 1/10
[OCT2017] Epoch 077/100 | lr_backbone=7.63e-06 lr_lora+head=7.63e-05 | train_loss=0.4498 train_acc=98.70% | val_loss=0.4642 val_acc=98.93% val_macroF1=98.05% | ep_time=157.6s peakVRAM=2.62GB
[ES] No improve 2/10
[OCT2017] Epoch 078/100 | lr_backbone=7.02e-06 lr_lora+head=7.02e-05 | train_loss=0.4459 train_acc=98.84% | val_loss=0.4654 val_acc=98.82% val_macroF1=97.89% | ep_time=157.6s peakVRAM=2.62GB
[ES] No improve 3/10
[OCT2017] Epoch 079/100 | lr_backbone=6.42e-06 lr_lora+head=6.42e-05 | train_loss=0.4455 train_acc=98.84% | val_loss=0.4656 val_acc=98.91% val_macroF1=98.01% | ep_time=157.6s peakVRAM=2.62GB
[ES] No improve 4/10
[OCT2017] Epoch 080/100 | lr_backbone=5.85e-06 lr_lora+head=5.85e-05 | train_loss=0.4463 train_acc=98.85% | val_loss=0.4652 val_acc=98.84% val_macroF1=97.89% | ep_time=157.7s peakVRAM=2.62GB
[ES] No improve 5/10
[OCT2017] Epoch 081/100 | lr_backbone=5.30e-06 lr_lora+head=5.30e-05 | train_loss=0.4471 train_acc=98.84% | val_loss=0.4641 val_acc=98.99% val_macroF1=98.14% | ep_time=157.5s peakVRAM=2.62GB
[ES] No improve 6/10
[OCT2017] Epoch 082/100 | lr_backbone=4.77e-06 lr_lora+head=4.77e-05 | train_loss=0.4450 train_acc=98.90% | val_loss=0.4655 val_acc=98.89% val_macroF1=97.95% | ep_time=157.6s peakVRAM=2.62GB
[ES] No improve 7/10
[OCT2017] Epoch 083/100 | lr_backbone=4.27e-06 lr_lora+head=4.27e-05 | train_loss=0.4454 train_acc=98.86% | val_loss=0.4655 val_acc=98.90% val_macroF1=97.97% | ep_time=157.7s peakVRAM=2.62GB
[ES] No improve 8/10
[OCT2017] Epoch 084/100 | lr_backbone=3.80e-06 lr_lora+head=3.80e-05 | train_loss=0.4427 train_acc=98.98% | val_loss=0.4666 val_acc=98.81% val_macroF1=97.82% | ep_time=157.7s peakVRAM=2.62GB
[ES] No improve 9/10
[OCT2017] Epoch 085/100 | lr_backbone=3.35e-06 lr_lora+head=3.35e-05 | train_loss=0.4437 train_acc=98.93% | val_loss=0.4659 val_acc=98.90% val_macroF1=97.98% | ep_time=157.5s peakVRAM=2.62GB
[ES] No improve 10/10
[OCT2017] Early stopping triggered.
[CAL] Fitting temperature scaling on VAL set...
[CAL] Learned temperature T = 0.5515

------------------------------------------------------------------------------------------
[OCT2017] TEST classification report (uncalibrated)
------------------------------------------------------------------------------------------
              precision    recall  f1-score   support

         CNV     0.8013    1.0000    0.8897       250
         DME     1.0000    0.9920    0.9960       250
      DRUSEN     0.9942    0.6800    0.8076       250
      NORMAL     0.9257    0.9960    0.9595       250

    accuracy                         0.9170      1000
   macro avg     0.9303    0.9170    0.9132      1000
weighted avg     0.9303    0.9170    0.9132      1000


==========================================================================================
[OCT2017] TEST summary (uncalibrated): Acc=91.70% MacroF1=91.32% ECE=0.0707 NLL=0.3012 Brier=0.1390
[OCT2017] Macro-AUC=0.9865
[OCT2017] TEMP-SCALED (T=0.552): ECE=0.0721 NLL=0.3702 Brier=0.1547
[OCT2017] Params trainable: 21,816,968 (100.0000%)
[OCT2017] Adapter-only size: 0.58 MB
[OCT2017] Inference latency (B=1): 10.913 ms/img (91.6 imgs/s), peakVRAM=0.23GB
[OCT2017] Inference throughput (B=64): 2632.2 imgs/s, peakVRAM=0.42GB
[OCT2017] Outputs saved in: runs\OCT2017\deit_small_lora_unfrozen_4c\20251227-082358
==========================================================================================

