{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d239a93-2fd4-49c1-973f-d3683688b357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Current folder: D:\\AIUB\\DSP\\Code\\Models\\DeiT-Small + AdaptFormer (MLP-parallel adapters)\n",
      "[OK] Found Summary.json files: 5\n",
      "[OK] Loaded runs: 5 | Failed: 0\n",
      "[OK] Saved: D:\\AIUB\\DSP\\Code\\Models\\DeiT-Small + AdaptFormer (MLP-parallel adapters)\\DeiT-Small + AdaptFormer (MLP-parallel adapters)_combined_summaries.json\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import datetime as dt\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "# -------------------- helpers --------------------\n",
    "\n",
    "def safe_get(d: Any, path: List[str], default: Any = None) -> Any:\n",
    "    cur = d\n",
    "    for k in path:\n",
    "        if not isinstance(cur, dict) or k not in cur:\n",
    "            return default\n",
    "        cur = cur[k]\n",
    "    return cur\n",
    "\n",
    "\n",
    "def load_json(path: Path) -> Tuple[Optional[Any], Optional[str]]:\n",
    "    try:\n",
    "        with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            return json.load(f), None\n",
    "    except Exception as e:\n",
    "        return None, f\"{type(e).__name__}: {e}\"\n",
    "\n",
    "\n",
    "def discover_summary_files(root: Path) -> List[Path]:\n",
    "    # finds Summary.json / summary.json / SUMMARY.JSON, etc., at ANY depth\n",
    "    return sorted([p for p in root.rglob(\"*\") if p.is_file() and p.name.lower() == \"summary.json\"])\n",
    "\n",
    "\n",
    "def normalize_run(raw: Dict[str, Any], source_path: Path, root: Path) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a consistent, AI-friendly view while preserving the original raw JSON.\n",
    "    Your Summary.json structure is like the attached example:\n",
    "    dataset/root/classes/model/peft/lora/params/storage/training/test_*/inference_benchmark.\n",
    "    \"\"\"\n",
    "    rel = source_path.resolve().relative_to(root.resolve())\n",
    "\n",
    "    facts = {\n",
    "        # identity\n",
    "        \"dataset\": safe_get(raw, [\"dataset\"]),\n",
    "        \"root\": safe_get(raw, [\"root\"]),\n",
    "        \"model\": safe_get(raw, [\"model\"]),\n",
    "        \"peft\": safe_get(raw, [\"peft\"]),\n",
    "        \"classes\": safe_get(raw, [\"classes\"]),\n",
    "        \"num_classes\": len(safe_get(raw, [\"classes\"], []) or []),\n",
    "\n",
    "        # lora/params/storage/training in a predictable compact layout\n",
    "        \"lora\": safe_get(raw, [\"lora\"]),\n",
    "        \"params\": safe_get(raw, [\"params\"]),\n",
    "        \"storage\": {\n",
    "            \"best_model_path\": safe_get(raw, [\"storage\", \"best_model_path\"]),\n",
    "            \"adapter_only_enabled\": safe_get(raw, [\"storage\", \"adapter_only_enabled\"]),\n",
    "            \"adapter_only_mb\": safe_get(raw, [\"storage\", \"adapter_only_mb\"]),\n",
    "            \"adapter_only_bytes\": safe_get(raw, [\"storage\", \"adapter_only_bytes\"]),\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"epochs_ran\": safe_get(raw, [\"training\", \"epochs_ran\"]),\n",
    "            \"best_val_loss\": safe_get(raw, [\"training\", \"best_val_loss\"]),\n",
    "            \"best_val_macro_f1\": safe_get(raw, [\"training\", \"best_val_macro_f1\"]),\n",
    "            \"total_train_time_sec\": safe_get(raw, [\"training\", \"total_train_time_sec\"]),\n",
    "            \"mean_epoch_time_sec\": safe_get(raw, [\"training\", \"mean_epoch_time_sec\"]),\n",
    "            \"peak_train_vram_gb\": safe_get(raw, [\"training\", \"peak_train_vram_gb\"]),\n",
    "        },\n",
    "\n",
    "        # tests (keep same naming as your files)\n",
    "        \"test_uncalibrated\": safe_get(raw, [\"test_uncalibrated\"]),\n",
    "        \"test_temp_scaled\": safe_get(raw, [\"test_temp_scaled\"]),\n",
    "\n",
    "        # inference\n",
    "        \"inference_benchmark\": safe_get(raw, [\"inference_benchmark\"]),\n",
    "        \"inference_quick\": {\n",
    "            \"b1_ms_per_img\": safe_get(raw, [\"inference_benchmark\", \"latency_batch1\", \"ms_per_img\"]),\n",
    "            \"b1_imgs_per_s\": safe_get(raw, [\"inference_benchmark\", \"latency_batch1\", \"imgs_per_s\"]),\n",
    "            \"b64_ms_per_img\": safe_get(raw, [\"inference_benchmark\", \"throughput_batchN\", \"ms_per_img\"]),\n",
    "            \"b64_imgs_per_s\": safe_get(raw, [\"inference_benchmark\", \"throughput_batchN\", \"imgs_per_s\"]),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"source\": {\n",
    "            \"relative_path\": str(rel).replace(\"\\\\\", \"/\"),\n",
    "            \"absolute_path\": str(source_path.resolve()),\n",
    "        },\n",
    "        \"facts\": facts,  # normalized for LLMs\n",
    "        \"raw\": raw,      # original JSON preserved\n",
    "    }\n",
    "\n",
    "\n",
    "def group_by_dataset(runs: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    by_ds: Dict[str, List[Dict[str, Any]]] = {}\n",
    "    for r in runs:\n",
    "        ds = safe_get(r, [\"facts\", \"dataset\"]) or \"UNKNOWN_DATASET\"\n",
    "        by_ds.setdefault(ds, []).append(r)\n",
    "\n",
    "    # sort within each dataset by macro_f1 (then acc) descending for readability\n",
    "    def score(run: Dict[str, Any]) -> float:\n",
    "        mf1 = safe_get(run, [\"facts\", \"test_uncalibrated\", \"macro_f1\"])\n",
    "        acc = safe_get(run, [\"facts\", \"test_uncalibrated\", \"acc\"])\n",
    "        try:\n",
    "            return float(mf1 if mf1 is not None else (acc if acc is not None else 0.0))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    for ds in by_ds:\n",
    "        by_ds[ds].sort(key=score, reverse=True)\n",
    "\n",
    "    return by_ds\n",
    "\n",
    "\n",
    "# -------------------- main (no args, Jupyter-friendly) --------------------\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "OUT_PATH = ROOT / f\"{ROOT.name}_combined_summaries.json\"\n",
    "\n",
    "summary_files = discover_summary_files(ROOT)\n",
    "\n",
    "runs: List[Dict[str, Any]] = []\n",
    "errors: List[Dict[str, Any]] = []\n",
    "\n",
    "for fp in summary_files:\n",
    "    obj, err = load_json(fp)\n",
    "    if err is not None:\n",
    "        errors.append({\"file\": str(fp.resolve()), \"error\": err})\n",
    "        continue\n",
    "    if not isinstance(obj, dict):\n",
    "        errors.append({\"file\": str(fp.resolve()), \"error\": f\"Expected dict, got {type(obj).__name__}.\"})\n",
    "        continue\n",
    "    runs.append(normalize_run(obj, fp, ROOT))\n",
    "\n",
    "combined = {\n",
    "    \"meta\": {\n",
    "        \"created_utc\": dt.datetime.utcnow().replace(microsecond=0).isoformat() + \"Z\",\n",
    "        \"search_root\": str(ROOT.resolve()),\n",
    "        \"output_file\": str(OUT_PATH.resolve()),\n",
    "        \"summary_files_found\": len(summary_files),\n",
    "        \"runs_loaded\": len(runs),\n",
    "        \"runs_failed\": len(errors),\n",
    "        \"note\": \"Each run includes (source, facts, raw). facts is normalized for AI; raw preserves original Summary.json.\",\n",
    "    },\n",
    "    \"runs\": runs,  # flat list is easiest for LLMs\n",
    "    \"by_dataset\": group_by_dataset(runs),\n",
    "    \"errors\": errors,\n",
    "}\n",
    "\n",
    "with OUT_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(combined, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"[OK] Current folder: {ROOT}\")\n",
    "print(f\"[OK] Found Summary.json files: {len(summary_files)}\")\n",
    "print(f\"[OK] Loaded runs: {len(runs)} | Failed: {len(errors)}\")\n",
    "print(f\"[OK] Saved: {OUT_PATH}\")\n",
    "if errors:\n",
    "    print(\"[WARN] Some files failed to load. See combined['errors'] in the output JSON.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ad587-07da-4125-8478-c4d194b7253c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
